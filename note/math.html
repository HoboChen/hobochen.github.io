<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"192217.space","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","width":280,"display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Calculus I (MIT 18.01) Differentiation Limit \[ \lim_{x\to a}f(x) &#x3D; L \iff \forall \epsilon&gt;0, \exists \delta &gt; 0: |f(x) - L| &lt; \epsilon , \forall x\in(a-\delta, a)\cup(a, a+\delta) \] Deriva">
<meta property="og:type" content="website">
<meta property="og:title" content="Jingqi Chen&#39;s Blog">
<meta property="og:url" content="https://192217.space/note/math.html">
<meta property="og:site_name" content="Jingqi Chen&#39;s Blog">
<meta property="og:description" content="Calculus I (MIT 18.01) Differentiation Limit \[ \lim_{x\to a}f(x) &#x3D; L \iff \forall \epsilon&gt;0, \exists \delta &gt; 0: |f(x) - L| &lt; \epsilon , \forall x\in(a-\delta, a)\cup(a, a+\delta) \] Deriva">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-10-17T23:02:18.516Z">
<meta property="article:modified_time" content="2024-10-17T23:02:18.516Z">
<meta property="article:author" content="Jingqi Chen">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://192217.space/note/math">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title> | Jingqi Chen's Blog
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Jingqi Chen's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-slide">

    <a href="/slide" rel="section"><i class="fa fa-desktop fa-fw"></i>Slides</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">
</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
          <h1 id="calculus-i-mit-18.01">Calculus I (<a
href="https://ocw.mit.edu/courses/18-01-single-variable-calculus-fall-2006">MIT
18.01</a>)</h1>
<h2 id="differentiation">Differentiation</h2>
<h3 id="limit">Limit</h3>
<p><span class="math display">\[
\lim_{x\to a}f(x) = L \iff \forall \epsilon&gt;0, \exists \delta &gt; 0:
|f(x) - L| &lt; \epsilon , \forall x\in(a-\delta, a)\cup(a, a+\delta)
\]</span></p>
<h3 id="derivative">Derivative</h3>
<p>The derivative is the slope of the line tangent to the graph of <span
class="math inline">\(f(x)\)</span>.</p>
<p>Tangent line is the <em>limit</em> of the secant line, as the
distance between the 2 points goes to zero.</p>
<p><span class="math display">\[
\lim_{\Delta x \to 0} \frac{\Delta f}{\Delta x} = \lim_{\Delta x \to 0}
\frac{f(x_0+\Delta x) - f(x_0)}{\Delta x} = f&#39;(x_0)
\]</span></p>
<p>Equivalent notations:</p>
<p><span class="math display">\[
\frac{\mathrm{d}f(x)}{\mathrm{d}x}, \frac {\mathrm{d}}{\mathrm{d}x}
f(x), f&#39;, Df
\]</span></p>
<h3 id="continuity">Continuity</h3>
<p><span class="math display">\[
\lim_{x\to x_0} f(x) = f(x_0) \iff f(x) \text{ is continuous at } x_0
\]</span></p>
<p>Different kinds of discontinuity:</p>
<ul>
<li>Removable: left hand limit equals to right hand limit, but not <span
class="math inline">\(f(x_0)\)</span> or <span
class="math inline">\(f(x_0)\)</span> is not defined.</li>
<li>Jump: both left hand limit to right hand limit exists, but not
equal.</li>
<li>Inifinite: both left hand limit to right hand limit exists, but not
the same infinity.</li>
<li>Other: left hand limit or right hand limit does not exist.</li>
</ul>
<p>Differentiable implies continuous as:</p>
<p><span class="math display">\[
\lim_{\Delta x \to 0} \Delta f(a+\Delta x) = f(a) \iff x = a,
\lim_{\Delta x \to 0} \Delta y = \lim_{\Delta x \to 0} \frac{\Delta
y}{\Delta x} \Delta x = (\lim_{\Delta x \to 0} \frac{\Delta y}{\Delta
x}) (\lim_{\Delta x \to 0} \Delta x) = \frac{\mathrm{d}y}{\mathrm{d}x}
\cdot0=0
\]</span></p>
<h3 id="conputations-of-derivatives">Conputations of derivatives</h3>
<p>basic:</p>
<p><span class="math display">\[
\begin{aligned}
    \mathrm{d}Cu &amp; = C \mathrm{d}u \\
    \mathrm{d}(u+v) &amp;= \mathrm{d}u + \mathrm{d}v \\
    \mathrm{d}(uv) &amp;= u \mathrm{d}v + v \mathrm{d}u \\
    \mathrm{d}\frac uv &amp;=\frac{v \mathrm{d}u-u\mathrm{d}v}{v^2}
\end{aligned}
\]</span></p>
<p>chain:</p>
<p><span class="math display">\[
\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{\mathrm{d}y}{\mathrm{d}u}\cdot\frac{\mathrm{d}u}{\mathrm{d}x}
\quad y=f(u) \text{ and } u = g(x)
\]</span></p>
<p>or in the form:</p>
<p><span class="math display">\[
[f(g(x))]&#39; = (f\circ g)&#39;(x) = f&#39;(g(x)) \cdot g&#39;(x)
\]</span></p>
<h3 id="higher-derivative-notation">Higher derivative notation</h3>
<p><span class="math display">\[
\begin{aligned}
    f^{&#39;&#39;}(x)  &amp; \quad y^{&#39;&#39;} &amp; \quad
\frac{\mathrm{d}^2y}{\mathrm{d} x^2} &amp; \quad \frac
{\mathrm{d}^2}{\mathrm{d} x ^ 2} f(x) \\
    f^{(n)}(x) &amp; \quad y^{n}  &amp; \quad
\frac{\mathrm{d}^ny}{\mathrm{d} x^n} &amp; \quad \frac
{\mathrm{d}^n}{\mathrm{d} x ^ n} f(x)
\end{aligned}
\]</span></p>
<h3 id="inplicit-differentication">Inplicit differentication</h3>
<p>Use the chain rule and treat the response variable cautiously.
Example: <span class="math inline">\(\mathrm{d}\tan^{-1}x\)</span>.</p>
<p><span class="math display">\[
\frac{f&#39;(t)}{f(t)} = \frac{\mathrm{d}}{\mathrm{d}t}\ln (f(t))
\]</span></p>
<h3 id="derivative-table">Derivative table</h3>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Func</th>
<th style="text-align: left;">Derivative</th>
<th style="text-align: left;">Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(C\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(0\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x \in
\mathbb{R}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(x^n\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(nx^{n-1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(n \in
\mathbb{R}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(a^x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\ln a\cdot
a^x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a\neq
1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(\log_ax\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\frac 1 {\ln
a} \cdot\frac{1}{x}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(a\neq
1\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\sin
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\cos
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x \in
\mathbb{R}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\cos
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(-\sin
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x \in
\mathbb{R}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\tan
x\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{\cos^2x}, \sec^2x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x\neq
\frac{\pi}{2}+k\pi, k\in\mathbb{Z}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\sec
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\sec x \tan
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x\neq
\frac{\pi}{2}+k\pi, k\in\mathbb{Z}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(\sin^{-1}x\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{\sqrt{1-x^2}}\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(x\in(-1,1)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(\tan^{-1}x\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{1+x^2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x \in
\mathbb{R}\)</span></td>
</tr>
</tbody>
</table>
<h3 id="lhospitals-rule">L'Hospital's rule</h3>
<p>If <span class="math inline">\(f(a) = g(a) = 0\)</span>, have
derivatives for <span class="math inline">\(x=a\)</span>, and <span
class="math inline">\(g&#39;(a) \neq 0\)</span>, then:</p>
<p><span class="math display">\[
\lim_{x\to a}\frac{f(x)}{g(x)} = \lim_{x\to a}
\frac{\frac{f(x)}{x-a}}{\frac{g(x)}{x-a}} =  \frac{\lim_{x\to
a}\frac{f(x) - f(a)}{x-a}}{\lim_{x\to a}\frac{g(x) - g(a)}{x-a}}
=\frac{f&#39;(a)}{g&#39;(a)}
\]</span></p>
<p>It is also ok to use L'Hospital's rule on limits of the form <span
class="math inline">\(\frac{\infty}{\infty}\)</span> or <span
class="math inline">\(x\to\pm\infty\)</span>.</p>
<h3 id="differential-notation">Differential notation</h3>
<p><span class="math display">\[
\mathrm{d}y = f&#39;(x)\mathrm{d}x \quad (y = f(x))
\]</span></p>
<p>Both <span class="math inline">\(\mathrm{d}y\)</span> and <span
class="math inline">\(f&#39;(x)\mathrm{d}x\)</span> are called
differentials.</p>
<h2 id="applications-of-differentiation">Applications of
Differentiation</h2>
<h3 id="linear-approximation">Linear approximation</h3>
<p><span class="math display">\[
f(x) \approx f(x_0) + f&#39;(x_0)(x-x_0), \quad x\approx x_0
\]</span></p>
<h3 id="newtons-method">Newton's method</h3>
<p>To solve <span class="math inline">\(f(x)=0\)</span>:</p>
<p><span class="math display">\[
x_{n+1} = x_n - \frac{f(x_n)}{f&#39;(x_n)}
\]</span></p>
<p>C implementation is <code>MIT-6.0001/3-newton.c</code>.</p>
<p>The mathematical theory providing conditions under which Newton's
method is guaranteed to succeed can be found in numerical analysis.</p>
<h3 id="mean-value-theorem">Mean value theorem</h3>
<p><span class="math display">\[
\exists c \in (a, b), f&#39;(c)=\frac{f(b) - f(a)}{b-a};
    f(x) \text{ is continuous}, x\in [a, b] \land
    f(x) \text{ is differentiable} , x\in  (a, b)
\]</span></p>
<h3 id="anti-derivaitive-table">Anti-derivaitive table</h3>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Func</th>
<th style="text-align: left;">Anti-derivative</th>
<th style="text-align: left;">Domain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(x^n\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\frac{x^{n+1}}{n+1}+c\)</span></td>
<td style="text-align: left;"><span class="math inline">\(n \neq
-1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\frac
1x\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\ln\|x\|+c\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(x\neq0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\sin
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(-\cos x
+c\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x \in
\mathbb{R}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\tan
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(-\ln(\cos x) +
c\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x\neq
\frac{\pi}{2}+k\pi, k\in\mathbb{Z}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\sec
x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\ln(\tan
x+\sec x) +c\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(x\in(-\frac{\pi}{2}+2k\pi,
\frac{\pi}{2}+2k\pi),k\in\mathbb{Z}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{\cos^2x}, \sec^2x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\tan
x+c\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x\neq
\frac{\pi}{2}+k\pi, k\in\mathbb{Z}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{\sqrt{1-x^2}}\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\sin^{-1}x\)</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(\frac{1}{1+x^2}\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\tan^{-1}x\)</span></td>
<td style="text-align: left;">-</td>
</tr>
</tbody>
</table>
<h3 id="differential-in-economics">Differential in economics</h3>
<p>Economics law, give <span class="math inline">\(C(x)\)</span> is
function of average cost:</p>
<p><span class="math display">\[
\frac{\mathrm{d}}{\mathrm{d}x}\frac{C(x)}{x} = 0 \iff
C&#39;(x)=\frac{C(x)}{x}
\]</span></p>
<p>Aka, if average cost reaches minium, then marginal cost = average
cost.</p>
<p>And, if profit reaches maxium, then marginal revenue = marginal
cost.</p>
<p>Elasticity of demand: <span class="math inline">\(E(p)=-\frac p x
\frac{\mathrm{d}x}{\mathrm{d}p}\)</span>.</p>
<h2 id="integration">Integration</h2>
<h3 id="riemann-sum">Riemann sum</h3>
<p><span class="math display">\[
\sum_{i=1}^{n}f(c_i)\Delta x
\]</span></p>
<h3 id="definite-integral">Definite integral</h3>
<p><span class="math display">\[
\lim_{n\to \infty}\sum_{i=1}^{n}f(c_i)\Delta x = \int^b_af(x) \mathrm d
x
\]</span></p>
<h3 id="first-fundamental-theorem-of-calculus">First fundamental theorem
of calculus</h3>
<p><span class="math display">\[
F(x) = \int_a^x f(t)\mathrm d t \land f(x) \text{ is continous} \implies
F&#39;(x) = f(x)
\]</span></p>
<h3 id="second-fundamental-theorem-of-calculus">Second fundamental
theorem of calculus</h3>
<p><span class="math display">\[
F&#39;(x) = f(x) \land f(x) \text{ is continous} \implies
\int^b_af(x) \mathrm d x=F(b)-F(a)
\]</span></p>
<h3 id="substitution">Substitution</h3>
<p>Given <span class="math inline">\(f(x) = g(u(x))\)</span>:</p>
<p><span class="math display">\[
\int g(u) \mathrm{d} u = \int g(u(x))u&#39;(x)\mathrm{d}x = \int
f(x)u&#39;(x) \mathrm{d}x
\]</span></p>
<p>For definite:</p>
<p><span class="math display">\[
\int_{x_1}^{x2} f(x)u&#39;(x) \mathrm{d}x = \int_{u(x_1)}^{u(x_2)} g(u)
\mathrm{d} u
\]</span></p>
<h3 id="trigonometric-function-integration">Trigonometric function
integration</h3>
<p><span class="math display">\[
\int \sin^n(x)\cos^m(x) \mathrm d x
\]</span></p>
<ol type="1">
<li>Either <span class="math inline">\(n\)</span> or <span
class="math inline">\(m\)</span> is odd; <span class="math inline">\(u =
\text{odd\_func}(x)\)</span>.</li>
<li><span class="math inline">\(n\)</span> and <span
class="math inline">\(m\)</span> are all even; use double angle formula
until 1 applies.</li>
</ol>
<p><span class="math display">\[
\int \sec^n(x)\tan^m(x) \mathrm d x
\]</span></p>
<ol type="1">
<li><span class="math inline">\(n\)</span> is even, <span
class="math inline">\(u = \tan x\)</span>.</li>
<li><span class="math inline">\(m\)</span> is odd, <span
class="math inline">\(u = \sec x\)</span>.</li>
<li><span class="math inline">\(n\)</span> is odd, <span
class="math inline">\(m\)</span> is even: a. <span
class="math inline">\(\tan^2 x + 1 = \sec^2 x\)</span> b. use the result
for <span class="math inline">\(\int \sec ^n x \mathrm d
x\)</span>.</li>
</ol>
<h3 id="partial-function-integration">Partial function integration</h3>
<p><span class="math inline">\(\frac{P(x)}{Q(x)}\)</span> can be
splitted in a systematic way.</p>
<p>Partial integral:</p>
<p><span class="math display">\[
(uv)&#39; = u&#39;v+uv&#39; \iff uv&#39;= (uv)&#39; - u&#39;v \iff \int
uv&#39; \mathrm d x = uv - \int u&#39;v \mathrm d x
\]</span></p>
<p>Examples:</p>
<ol type="1">
<li><span class="math inline">\(\int (\ln x)^n \mathrm d x\)</span></li>
<li><span class="math inline">\(\int x^n \mathrm e ^ x \mathrm d
x\)</span></li>
<li><span class="math inline">\(\int \sin x \mathrm e ^ x \mathrm d
x\)</span></li>
<li><span class="math inline">\(\int \cos x \mathrm e ^ x \mathrm d
x\)</span></li>
<li><span class="math inline">\(\int \sec ^n x \mathrm d x\)</span></li>
</ol>
<h3 id="improper-integral">Improper integral</h3>
<p><span class="math display">\[
\int_{a}^{\infty} f(x) \mathrm d x = \lim_{x\to\infty}F(x)\mathrm d x
\]</span></p>
<p>is said to converge is the limit exists.</p>
<h2 id="applications-of-integral">Applications of Integral</h2>
<h3 id="area-between-2-curves">Area between 2 curves</h3>
<p><span class="math display">\[
A = \int_a^b(f(x)-g(x))\mathrm d x
\]</span></p>
<h3 id="volume-by-slice-method">Volume by slice method</h3>
<p>To get the volume of a function revolved about <span
class="math inline">\(x\)</span>-axis:</p>
<p><span class="math display">\[
\mathrm d V = \pi f(x)^2 \mathrm d x
\]</span></p>
<h3 id="volume-by-disk-method">Volume by disk method</h3>
<p>To get the volume of a function revolved about <span
class="math inline">\(y\)</span>-axis:</p>
<p><span class="math display">\[
\mathrm d V = \pi x^2 \mathrm dy
\]</span></p>
<h3 id="volume-by-cylinder-method">Volume by cylinder method</h3>
<p>To get the volume of a function revolved about <span
class="math inline">\(y\)</span>-axis:</p>
<p><span class="math display">\[
\mathrm d V = 2\pi x y \mathrm dx
\]</span></p>
<h3 id="weighted-average">Weighted average</h3>
<p><span class="math display">\[
\frac{\int_a^bf(x)w(x)\mathrm d x}{\int_a^bw(x)\mathrm d x}
\]</span></p>
<h3 id="simpsons-method">Simpson's method</h3>
<p>For numerical integration:</p>
<p><span class="math display">\[
\int_{a}^{b} f(x) \mathrm d x = \frac{b - a}{6}[f(a) + 4f(\frac{a+b}{2})
+ f(b)] + \mathcal{O}((b-a)^4)
\]</span></p>
<p>C implementation is
<code>MIT-6.0001/18.01-simpson-integral.c</code>.</p>
<h3 id="arc-length">Arc length</h3>
<p><span class="math display">\[
L = \int \mathrm d s =\int_{x_0}^{x_1}\sqrt{1+(\frac{dy}{dx})^2}\mathrm
d x
\]</span></p>
<h3 id="surface-area-of-a-function-revolved-about-x-axis">Surface area
of a function revolved about <span
class="math inline">\(x\)</span>-axis</h3>
<p><span class="math display">\[
S = \int 2\pi y \mathrm d s
\]</span></p>
<h3 id="area-in-polar-coordinates">Area in polar coordinates</h3>
<p><span class="math display">\[
S = \int^{\theta_2}_{\theta_1}\frac 1 2 r^2 \mathrm d \theta
\]</span></p>
<h2 id="series">Series</h2>
<h3 id="sequence">Sequence</h3>
<p>A sequence is said to be <em>bounded</em> if there are 2 numbers
<span class="math inline">\(A, B\)</span> such that <span
class="math inline">\(A\leq x_n \leq B\)</span> for every <span
class="math inline">\(n\)</span>.</p>
<p>A sequence is said to be <em>convergent</em> if it has a limit, aka,
<span class="math inline">\(\forall \epsilon&gt;0, \exists n_0:
|x_n-L|&lt;\epsilon, \forall n&gt;n_0\)</span>.</p>
<p><span class="math display">\[
\mathrm{convergent} \implies \mathrm{bounded}
\]</span></p>
<p>An increasing sequence converges if and only if it is bounded.</p>
<h3 id="series-1">Series</h3>
<p><span class="math display">\[
s_n = \sum_i a_i
\]</span></p>
<p>is called <em>infinite series</em>, or simply <em>series</em>. <span
class="math inline">\(a_i\)</span> is called terms.</p>
<p>If the sequence <span class="math inline">\(\{s_n\}\)</span>
converges, then the series converges.</p>
<p>Geometric series:</p>
<p><span class="math display">\[
\begin{aligned}
a_n  &amp; = x ^n \\
s_n &amp; = \frac{1-x^{n+1}}{1-x}
\end{aligned}
\]</span></p>
<p>It converges for <span class="math inline">\(|x| &lt; 1\)</span>.</p>
<h3 id="ratio-test-and-root-test">Ratio test and root test</h3>
<p>If <span class="math inline">\(\sum a_n\)</span> is a series of
positive terms, given <span class="math inline">\(L = \lim_{n\to
\infty}\frac {a_{n+1}}{a_n}\)</span>, then:</p>
<ul>
<li><span class="math inline">\(L &lt; 1 \to
\text{converge}\)</span></li>
<li><span class="math inline">\(L &gt; 1 \to
\text{diverge}\)</span></li>
<li><span class="math inline">\(L=1 \to \text{inconclusive}\)</span>:
e.g. <span class="math inline">\(a_n=\frac 1 {n^p}\)</span></li>
</ul>
<p>Given sum of geometric series converges for <span
class="math inline">\(r\in (0,1)\)</span>, given <span
class="math inline">\(L = \lim_{n\to \infty} (a_n)^{\frac 1 n}\)</span>,
then:</p>
<ul>
<li><span class="math inline">\(L &lt; 1 \to
\text{converge}\)</span></li>
<li><span class="math inline">\(L &gt; 1 \to
\text{diverge}\)</span></li>
<li><span class="math inline">\(L=1 \to
\text{inconclusive}\)</span></li>
</ul>
<h3 id="alternating-series-test">Alternating series test</h3>
<p>For <span
class="math inline">\(\sum_{n=1}^{\infty}(-1)^{n+1}a_n\)</span>:</p>
<ul>
<li><span class="math inline">\(a_n\)</span> is not increasing</li>
<li><span class="math inline">\(a_n \to 0\)</span></li>
</ul>
<p>A series <span class="math inline">\(\sum a_n\)</span> is said to be
<em>absolutely convergent</em> if <span class="math inline">\(\sum
|a_n|\)</span> converges.</p>
<p><span class="math display">\[
\text{absolute convergence} \to \text{convergence}
\]</span></p>
<h3 id="power-series">Power series</h3>
<p><span class="math display">\[
s_n = \sum_{n=0}^{\infty}a_nx^n
\]</span></p>
<p>where the <span class="math inline">\(a_n\)</span> are constants and
<span class="math inline">\(x\)</span> is variable. Geometric series is
the simplest power series.</p>
<!-- If a power series $\sum a_nx^n$ converges at $x_1$, $x_1 \neq 0$, then it converges absolutely for all  $|x| < |x_1|$; and if it diverges at $x_1$, then it diverges for all $|x| > |x_1|$. -->
<p>Every power series <span class="math inline">\(\sum a_nx^n\)</span>
has a radius of convergence <span class="math inline">\(R\)</span>,
where <span class="math inline">\(0 \leq R \leq \infty\)</span>, with
the property that the series converges absolutely if <span
class="math inline">\(|x| &lt; R\)</span> and diverges if <span
class="math inline">\(|x| &gt; R\)</span>:</p>
<p><span class="math display">\[
R = \lim_{n\to\infty}|\frac{a_n}{a_{n+1}}|
\]</span></p>
<p>Within the radius of convergence, the powerseries is
<em>continuous</em>, <em>differentiable</em> and
<em>integrable</em>.</p>
<h3 id="integral-comparison">Integral comparison</h3>
<p>Consider a positive, decreasing function <span
class="math inline">\(f(x) &gt; 0\)</span>, per upper and lower Riemann
Sum:</p>
<p><span class="math display">\[
|\sum_{n=1}^{\infty} f(n) - \int_1^\infty f(x)\mathrm d x| &lt; f(1)
\]</span></p>
<p>So, for <span class="math inline">\(s_n = \sum_i f_i\)</span> and
<span class="math inline">\(\int_1^\infty f(x)\mathrm d x\)</span>,
either both converge or both diverge.</p>
<h3 id="eulers-constant">Euler's constant</h3>
<p>As in integral comparison, there is <span class="math inline">\(F(n)
= \sum_1^n a_n - \int_1^nf(x) \mathrm d x\)</span>, and <span
class="math inline">\(0 \leq F(n) \leq a_1\)</span>. <span
class="math inline">\(F(n)\)</span> is decreasing and <span
class="math inline">\(L = \lim_{n\to\infty}F(n)\)</span> exists. The
application is:</p>
<p><span class="math display">\[
\text{Euler&#39;s constant } \gamma = \lim_{n\to\infty} (\sum_{i=1}^{n}
\frac 1 i - \int_{1}^{n}\frac 1 x \mathrm d x)
\]</span></p>
<h3 id="taylors-series">Taylor's series</h3>
<p>At <span class="math inline">\(x=0\)</span>:</p>
<p><span class="math display">\[
f(x)=\sum_{i=0}^{n}\frac{f^{(i)}(0)}{i!}x^i +R_n(x)
\]</span></p>
<p>Or <span class="math inline">\(x=x_0\)</span>:</p>
<p><span class="math display">\[
f(x)=\sum_{i=0}^{\infty}\frac{f^{(i)}(x_0)}{i!}(x-x_0)^i \]</span></p>
<p>Derivative remainder of Taylor's formula:</p>
<p><span class="math display">\[
R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}, c \in(0,x)
\]</span></p>
<p>The Taylor's series converges to <span
class="math inline">\(f(x)\)</span> if and only if:</p>
<p><span class="math display">\[
\lim_{n\to\infty}R_n(x)=0
\]</span></p>
<p>After operations of Taylor's series of <span
class="math inline">\(\sin x, \cos x, \mathrm e^x\)</span>:</p>
<p><span class="math display">\[
\mathrm e ^ {ix}=\cos x + i \sin x \implies \mathrm e ^ {i\pi} + 1 = 0
\]</span></p>
<h2 id="miscellaneous">Miscellaneous</h2>
<h3 id="mathrme"><span class="math inline">\(\mathrm{e}\)</span></h3>
<p><span class="math display">\[
\frac {\mathrm{d}} {\mathrm{d} x}a^x = a^x \to a=\mathrm{e}\iff
\lim_{\Delta x \to0}\frac{\mathrm{e}^{\Delta x}-1}{\Delta x} = 1 \iff
\mathrm{e}=\lim_{n\to \infty} (1+\frac 1 n)^n, n=\frac 1 {\Delta x}
\]</span></p>
<p>It is easy to prove <span
class="math inline">\(f(x)=c\mathrm{e}^x\)</span> is the only function
<span class="math inline">\(f&#39;(x)=f(x)\)</span> other than trivial
<span class="math inline">\(f(x)=0\)</span>.</p>
<h3 id="int_-inftyinftye-x2mathrm-d-x"><span
class="math inline">\(\int_{-\infty}^{\infty}e^{-x^2}\mathrm d
x\)</span></h3>
<p>Volume by slice method for</p>
<ol type="1">
<li>V = volume under <span class="math inline">\(e^{-r^2} (r =
\sqrt{x^2+y^2}\)</span> = <span class="math inline">\(\pi\)</span></li>
<li>To prove <span class="math inline">\(V =
(\int_{-\infty}^{\infty}e^{-x^2}\mathrm d x)^2\)</span> using
slice.</li>
</ol>
<h3 id="maximum-overhung">Maximum overhung</h3>
<p><a href="https://math.dartmouth.edu/~pw/papers/maxover.pdf">Paterson
et al. (2007)</a></p>
<h3 id="real-number-system">Real number system</h3>
<p>The axiomatic approach (I prefer this <a
href="https://www.quora.com/What-are-the-axioms-of-real-numbers-and-their-properties">quora
answer</a>):</p>
<p>They are an Abelian Group under addition:</p>
<ul>
<li>Commutative <span class="math inline">\(x+y=y+x\)</span></li>
<li>Associative <span
class="math inline">\((x+y)+z=x+(y+z)\)</span></li>
<li>Identity <span class="math inline">\(x+0=0+x=x\)</span></li>
<li>Inverse <span class="math inline">\(\forall x \exists
y:x+y=0\)</span></li>
</ul>
<p>Excluding zero they are an Abelian Group under multiplication:</p>
<ul>
<li>Commutative <span class="math inline">\(x\cdot y=y\cdot
x\)</span></li>
<li>Associative <span class="math inline">\((x\cdot y)\cdot z=x\cdot
(y\cdot z)\)</span></li>
<li>Identity <span class="math inline">\(x\cdot1=1\cdot
x=x\)</span></li>
<li>Inverse <span class="math inline">\(\forall x\neq0\exists y:x\cdot
y=1\)</span></li>
</ul>
<p>Multiplication distributes over addition:</p>
<ul>
<li><span class="math inline">\(x\cdot (y+z)=(x\cdot y)+(x\cdot
z)\)</span></li>
<li><span class="math inline">\((x+y)\cdot z=(x\cdot z)+(y\cdot
z)\)</span></li>
</ul>
<p>They are totally ordered:</p>
<ul>
<li><span class="math inline">\(x&lt;y\)</span> or <span
class="math inline">\(y&lt;x\)</span> or <span
class="math inline">\(x=y\)</span></li>
<li><span class="math inline">\(x&lt;y\to x+z&lt;y+z\)</span></li>
<li><span class="math inline">\(x\geq 0\land y\geq 0\to xy\geq
0\)</span></li>
</ul>
<p>They are dedekind-complete (have the least-upper-bound property):</p>
<ul>
<li>Every non-empty bounded subset has a least upper bound.</li>
</ul>
<p>It turns out that any structure satisfying these axioms is
isomorphic, so we call any such structure <em>the</em> Real numbers,
<span class="math inline">\((\mathbb{R},+,\cdot )\)</span>. In short
<span class="math inline">\(\mathbb{R}\)</span> is the dedekind-complete
ordered Field.</p>
<h1 id="calculus-ii-mit-18.02">Calculus II (<a
href="https://ocw.mit.edu/courses/18-02-multivariable-calculus-fall-2007/pages/calendar/">MIT
18.02</a>)</h1>
<h2 id="vectors-and-matrices">Vectors and Matrices</h2>
<h3 id="product">Product</h3>
<p><span class="math display">\[
\begin{aligned}
    \vec A \cdot \vec B &amp; = \sum a_ib_i = |\vec A||\vec B| \cos
\theta \\
    \vec A \times \vec B &amp; =
        \begin{vmatrix}
            \vec i &amp; \vec j &amp; \vec k \\
            a_1 &amp; a_2 &amp; a_3 \\
            b_1 &amp; b_2 &amp; b_3
        \end{vmatrix} = \vec i
            \begin{vmatrix}
                a_2 &amp; a_3 \\
                b_2 &amp; b_3
            \end{vmatrix}
        - \vec j
            \begin{vmatrix}
                a_1 &amp; a_3 \\
                b_1 &amp; b_3
            \end{vmatrix}
        + \vec k
            \begin{vmatrix}
                a_1 &amp; a_2 \\
                b_1 &amp; b_2
            \end{vmatrix} \\
    |\vec A \times \vec B| &amp; = \text{area of space paralleogram} \\
    \frac{\vec A \times \vec B}{|\vec A \times \vec B|} &amp;= \hat
n\text{ perpendicular to plane formed by } \vec A \text{ and } \vec B \\
\end{aligned}
\]</span></p>
<h3 id="determinant">Determinant</h3>
<p><span class="math display">\[
\begin{aligned}
    |\det(\vec A, \vec B)| &amp; = \text {area of parallelogram} \\
    |\det(\vec A, \vec B, \vec C)| &amp; = \text {area of
parallelepiped}
\end{aligned}
\]</span></p>
<h3 id="inverse-matrix">Inverse matrix</h3>
<p><span class="math display">\[
\mathbf{A}^{-1} = \frac{1}{\det({\mathbf{A}})}\text{adj}(\mathbf{A})
\]</span></p>
<h2 id="partial-derivatives">Partial Derivatives</h2>
<h3 id="partial-derivaitives">Partial derivaitives</h3>
<p>To treat all other variables as constant:</p>
<p><span class="math display">\[
f_x = \frac{\partial f}{\partial x} = \lim_{\Delta x \to 0}
\frac{f(x_0+\Delta x, y_0) - f(x_0, y_0)}{\Delta x}
\]</span></p>
<h3 id="least-square">Least square</h3>
<p>To find the the best-fit line <span class="math inline">\(y = ax +
b\)</span> for <span class="math inline">\(x_i, y_i\)</span>:</p>
<p><span class="math display">\[
\text{min } [ D_{a, b} = \sum_i (y_i - (ax_i + b)) ^ 2 ] \iff
\frac{\partial D}{\partial a} = \frac {\partial D}{\partial b} = 0
\]</span></p>
<h3 id="minmax">Min/max</h3>
<p>Look at second derivatives, <span class="math inline">\(f_{xx} =
\frac{\partial^2 f}{\partial x^2}, f_{xy}, f_{yx}, f_{yy}\)</span>,
fact(<a
href="https://en.wikipedia.org/wiki/Symmetry_of_second_derivatives">Clairaut's
theorem</a>): <span class="math inline">\(f_{xy} = f_{yx}\)</span>.</p>
<p>Given <span class="math inline">\(f\)</span> and critical point <span
class="math inline">\((x_0, y_0)\)</span>, let <span
class="math inline">\(A = f_{xx}(x_0, y_0), B = f_{xy}(x_0, y_0), C =
f_{yy}(x_0, y_0)\)</span>, then:</p>
<ul>
<li><span class="math inline">\(AC - B^2 &gt; 0\)</span>: <span
class="math inline">\(A&gt;0\)</span> local min, <span
class="math inline">\(A&lt;0\)</span> local max</li>
<li><span class="math inline">\(AC - B^2 &lt; 0\)</span>: saddle</li>
<li><span class="math inline">\(AC - B^2 = 0\)</span>: see higher
derivative</li>
</ul>
<h3 id="taylors-theorem">Taylor's theorem</h3>
<p>For <span class="math inline">\(f:\mathbb{R}^n\to\mathbb{R}\)</span>,
which is <span class="math inline">\(k\)</span>-times continously
differentiable at <span class="math inline">\(\mathbf{x_0} \in
\mathbb{R}^n\)</span>, then there exists function <span
class="math inline">\(h_\alpha:\mathbb{R}^n\to\mathbb{R}\)</span>, where
<span class="math inline">\(|\alpha| = k\)</span>, such that:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{|\alpha| \leq k} \frac {D^\alpha f(\mathbf
x_0)}{\alpha!}(\mathbf{x} - \mathbf{x_0})^\alpha + \sum_{|\alpha| =
k}h_\alpha(\mathbf x)(\mathbf{x} - \mathbf{x_0})^\alpha \\
\text{ and } \lim_{\mathbf{x}\to\mathbf{x_0}}h_\alpha(\mathbf{x}) = 0
\]</span></p>
<h3 id="total-differential">Total differential</h3>
<p>For <span class="math inline">\(f = f(x, y, z)\)</span>:</p>
<p><span class="math display">\[
\mathrm d f = f_x \mathrm d x + f_y \mathrm d y + f_z \mathrm d z
\]</span></p>
<h3 id="chain-rule">Chain rule</h3>
<p>For <span class="math inline">\(f = f(x, y, z), x = x(t), y = y(t), z
= z(t)\)</span>:</p>
<p><span class="math display">\[
\frac{\mathrm d f}{\mathrm d t} =
f_x \frac{\mathrm d x}{\mathrm d t} + f_y \frac{\mathrm d y}{\mathrm d
t} + f_z \frac{\mathrm d z}{\mathrm d t}
\]</span></p>
<p>For <span class="math inline">\(w = f(x, y), x = x(u, v), y = y(u,
v)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    \mathrm d w &amp; = f_x \mathrm d x + f_y \mathrm d y = f_x (x_u
\mathrm d u + x_v \mathrm d v) + f_y (y_u \mathrm d u + y_v \mathrm d v)
\\
    \implies \frac{\partial f}{\partial u} &amp; = f_x x_u + f_y y_u =
\frac{\partial f}{\partial x}\frac{\partial x}{\partial u} +
\frac{\partial f}{\partial y}\frac{\partial y}{\partial u} \\
\end{aligned}
\]</span></p>
<h3 id="gradient-vector">Gradient vector</h3>
<p>For <span class="math inline">\(w = w(x, y, z), x = x(t), y = y(t), z
= z(t)\)</span>, to be perpendicular to the level surfaces <span
class="math inline">\(w = c\)</span>:</p>
<p><span class="math display">\[
\nabla w = \langle w_x, w_y, w_z \rangle
\]</span></p>
<!-- Level surface of $w = (x, y, z)$ -->
<h3 id="rate-of-change-in-an-arbitrary-direction">Rate of change in an
arbitrary direction</h3>
<p>For <span class="math inline">\(w\)</span> as move in <span
class="math inline">\((x, y)\)</span>:</p>
<p><span class="math display">\[
\frac{\mathrm d w}{\mathrm d s | \hat{u}} = \nabla w \cdot \hat{u} =
|\nabla w|\cos \theta
\]</span></p>
<h3 id="lagarange-multipliers">Lagarange multipliers</h3>
<p>To get min/max of <span class="math inline">\(w = w(x, y, z)\)</span>
given <span class="math inline">\(g(x, y, z) = c\)</span>:</p>
<p><span class="math display">\[
\nabla f = \lambda \nabla g
\]</span></p>
<h3 id="partial-derivative-with-non-indenpendent-variables">Partial
derivative with non-indenpendent variables</h3>
<p>If <span class="math inline">\(f = f(x, y, z), g(x, y, z) =
c\)</span>, ask for <span class="math inline">\((\frac{\partial
f}{\partial z})_{y}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; \mathrm d g = 0 \to g_x\mathrm d x + g_y\mathrm d y + g_z
\mathrm d z = 0 \\
    &amp; \mathrm d y = 0 \to g_x\mathrm d x + g_z \mathrm d z = 0 \iff
dx = -\frac{g_z \mathrm d z}{g_x} \\
    &amp; \begin{aligned}
        \mathrm d f &amp;= f_x\mathrm d x + f_y\mathrm d y + f_z \mathrm
d z \\
        &amp; = f_x\mathrm d x + f_z \mathrm d z \\
        &amp; = f_x(-\frac{g_z \mathrm d z}{g_x}) + f_z \mathrm d z \\
        &amp; = \frac{f_zg_x-f_xg_z}{g_x}\mathrm d z
    \end{aligned} \\
    &amp; \implies (\frac{\partial f}{\partial z})_{y} =
\frac{g_xf_z-f_xg_z}{g_x}
\end{aligned}
\]</span></p>
<h2 id="double-integral-in-plane">Double Integral in Plane</h2>
<h3 id="double-integral">Double integral</h3>
<p>For the volume below <span class="math inline">\(z = f(x, y)\)</span>
over plane region <span class="math inline">\(R\)</span>:</p>
<p><span class="math display">\[
\iint _{R}f(x, y)\mathrm d A = \iint_{\min y}^{\max y} f(x, y) \mathrm
dy \mathrm d x
\]</span></p>
<h3 id="polar-coordinates">Polar coordinates</h3>
<p><span class="math display">\[
\mathrm d A = r\mathrm d r \mathrm d \theta
\]</span></p>
<h3 id="area-of-region">Area of region</h3>
<p><span class="math display">\[
\iint_R1\mathrm d A
\]</span></p>
<h3 id="center-of-mass">Center of mass</h3>
<p>With density function <span class="math inline">\(\delta(x,
y)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    \overline x = \frac{1}{\iint_R \delta \mathrm d A} \iint_R x\delta
\mathrm d A \\
    \overline y = \frac{1}{\iint_R \delta \mathrm d A} \iint_R y\delta
\mathrm d A
\end{aligned}
\]</span></p>
<h3 id="rotational-moment-of-inertia">Rotational moment of inertia</h3>
<p><span class="math display">\[
I = \iint_R (\text{distance to axis})^2\delta \mathrm d A
\]</span></p>
<h3 id="jcaobian-matrix">Jcaobian matrix</h3>
<p>For <span class="math inline">\(u=u(x, y), v = v(x, y)\)</span>:</p>
<p><span class="math display">\[
\mathbf{J} = \frac{\partial(u, v)}{\partial(x, y)}=
    \begin{vmatrix}
        u_x &amp; u_y \\
        v_x &amp; v_y
    \end{vmatrix}
\]</span></p>
<p>More generally for <span
class="math inline">\(\mathbf{f}:\mathbb{R}^n\rightarrow\mathbb{R}^m:
\mathbf{x}\in\mathbb{R}^n, \mathbf{f(x)} \in \mathbb{R}^m\)</span>:</p>
<p><span class="math display">\[
\mathbf{J}_{ij} = \frac{\partial f_i}{\partial x_j}
\]</span></p>
<h3 id="change-of-variables">Change of variables</h3>
<p>For <span class="math inline">\(u=u(x, y), v = v(x, y)\)</span>:</p>
<p><span class="math display">\[
\mathrm d u \mathrm d v = |\mathbf{J}| \mathrm d x \mathrm d y
\]</span></p>
<h2 id="line-integral-in-plane">Line Integral in Plane</h2>
<h3 id="vector-fields">Vector fields</h3>
<p><span class="math display">\[
\vec{F} = M \mathbf{\hat{i}} + N \mathbf{\hat{j}}, M = M(x,y), N = N(x,
y)
\]</span></p>
<h3 id="line-integral">Line integral</h3>
<p>W is force multiply distance, <span class="math inline">\(W =
\vec{F}\cdot \Delta \vec{r}\)</span>, for a small motion <span
class="math inline">\(\Delta \vec{r}\)</span>, total work:</p>
<p><span class="math display">\[
\begin{aligned}
    W &amp;= \lim_{\Delta \vec{r}\to0}\sum_i{\vec F \cdot \Delta
\vec{r_i}}\\
    &amp;= \int_C\vec{F}\cdot \mathrm d \vec{r} \\
    &amp;= \int_C M \mathrm d x + N \mathrm d y \\
    &amp;= \int_C \vec F \cdot \mathbf{\hat T} \mathrm d s
\end{aligned}
\]</span></p>
<h3 id="fundamental-theorem-of-calculus-for-line-integrals">Fundamental
theorem of calculus for line integrals</h3>
<p><span class="math inline">\(\vec F = \nabla f\)</span> is called
<em>gradient field</em>, <span class="math inline">\(f\)</span> is
called <em>potential function</em>.</p>
<p><span class="math display">\[
\int_C \nabla f \cdot \mathrm d \vec r = f(P_1) - f(P_0), C \text{ is
curve from } P_0 \text{ to } P_1 \text{ .}
\]</span></p>
<p>Consequences:</p>
<ol type="1">
<li>Path indenpendence</li>
<li>Conservativeness</li>
</ol>
<!-- $$
\vec F = \nabla f = \langle M, N\rangle \to M_y = N_x
$$

$$
\vec F = \langle M, N\rangle \text{ is defined and differentiable } \land M_y = N_x \to \vec F = \nabla f
$$ -->
<p><span class="math inline">\(N_x = M_y {\iff}^* \vec F \text{ is a
gradient field } \iff \vec F \text{ is conservative: } \oint_C \vec F
\cdot \mathrm d \vec r = 0 \text{ for any closed curve}\)</span></p>
<p><span class="math inline">\(*\)</span> only holds if <span
class="math inline">\(\vec F\)</span> is defined everywhere or in a
<em>simply-connected</em> region, see below.</p>
<h3 id="curl">Curl</h3>
<p><span class="math display">\[
curl(\vec F) = N_x - M_y
\]</span></p>
<h3 id="greens-theorem">Green's theorem</h3>
<p><span class="math display">\[
\begin{aligned}
\oint_C \vec F \cdot \mathrm d \vec r = \iint_R curl(\vec F) \mathrm d A
\iff &amp; \oint_C M \mathrm d x + N \mathrm d y = \iint_R (N_x -
M_y)\mathrm d A \\
\iff &amp; \oint_C M \mathrm d x = \iint_R - M_y \mathrm d A \land
\oint_C N \mathrm d y = \iint_R N_x \mathrm d A
\end{aligned}
\]</span></p>
<h3 id="flux">Flux</h3>
<p><span class="math display">\[
\begin{aligned}
    F &amp;= \lim_{\Delta \vec{r}\to0}\sum_i{(\vec F \cdot \mathbf{\hat
n}) \Delta \vec{s_i}} \\
    &amp;= \int_C \vec F \cdot \mathbf{\hat n} \mathrm d s \\
    &amp;=\int_C \vec F \cdot \langle \mathrm d y, -\mathrm d x \rangle
\\
    &amp;= \int_C -N\mathrm d x + M \mathrm d y
\end{aligned}
\]</span></p>
<h3 id="div">Div</h3>
<p><span class="math display">\[
div(\vec F) = M_x + N_y
\]</span></p>
<h3 id="greens-theorem-for-flux">Green's theorem for flux</h3>
<p><span class="math display">\[
\oint_C \vec F \cdot \mathbf{\hat n} \mathrm d s = \iint_R div(\vec F)
\mathrm d A \iff \oint_C -N\mathrm d x + M \mathrm d y  = \iint_R M_x +
N_y\mathrm d A
\]</span></p>
<p><em>Simply-connected</em> region is a region R if, given any closed
curve in R, the interior region is entirely contained in R.</p>
<h2 id="triple-integrals-and-surface-integrals-in-3d-space">Triple
Integrals and Surface Integrals in 3D-Space</h2>
<h3 id="triple-integrals">Triple integrals</h3>
<p><span class="math display">\[
\iiint_R f \mathrm d V
\]</span></p>
<p>Appllications are similar to 2-space integrals: mass, center of mass,
inertia, etc.</p>
<h3 id="cylindrical-and-spherical-coordinates">Cylindrical and spherical
coordinates</h3>
<p>Cylindrical coordinates <span class="math inline">\((r, \theta,
z)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
    x &amp;= r \cos \theta \\
    y &amp;= r \sin \theta
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\mathrm d V = r\mathrm dr\mathrm d \theta \mathrm d z
\]</span></p>
<p>Spherical coordinates <span class="math inline">\((\rho, \phi,
\theta)\)</span>:</p>
<p><span class="math display">\[
\begin{array}{l}
    \begin{aligned}
        \rho &amp;= \text{distance to origin} \\
        \phi &amp;= \text{angle down from } z \\
        \theta &amp;= \text{same as cylindrical}
    \end{aligned}
\end{array}
    \implies
\begin{array}{l}
    \begin{aligned}
        z &amp;= \rho \cos \phi \\
        r &amp;= \rho \sin \phi
    \end{aligned}
\end{array}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\mathrm d S &amp; = r^2\sin\phi \mathrm d \phi \mathrm d \theta\\
\mathrm d V &amp; = \rho^2\sin\phi\mathrm d \rho \mathrm d \phi \mathrm
d \theta \\
\end{aligned}
\]</span></p>
<h3 id="vector-fields-in-3d-space">Vector fields in 3D space</h3>
<p><span class="math display">\[
\vec{F} = P \mathbf{\hat{i}} + Q \mathbf{\hat{j}} +  R \mathbf{\hat{k}},
P = P(x,y, z),  Q = Q(x, y, z), R = R(x, y, z)
\]</span></p>
<h3 id="flux-in-3d-space">Flux in 3D space</h3>
<p><span class="math display">\[
F = \iint_S \vec{F}\cdot\mathbf{\hat{n}}\mathrm d S
\]</span></p>
<p>For plane <span class="math inline">\(z = f(x, y)\)</span>:</p>
<p><span class="math display">\[
\mathbf{\hat{n}}\mathrm d S = \pm \langle -f_x, -f_y, 1 \rangle \mathrm
d x \mathrm d y
\]</span></p>
<p>For plane <span class="math inline">\(x = x(u, v), y = y(u, v), z =
z(u, v)\)</span>:</p>
<p><span class="math display">\[
\mathbf{\hat{n}}\mathrm d S = \pm \langle \frac{\partial x}{\partial u},
\frac{\partial y}{\partial u} , \frac{\partial z}{\partial u} \rangle
\times \langle \frac{\partial x}{\partial v}, \frac{\partial y}{\partial
v}, \frac{\partial z}{\partial v} \rangle \mathrm d u \mathrm d v = \pm
\frac{\partial\vec{r}}{\partial u}\times\frac{\partial\vec{r}}{\partial
v} \mathrm d u \mathrm d v
\]</span></p>
<p>For plane <span class="math inline">\(w(x, y, z) = c\)</span></p>
<p><span class="math display">\[
\begin{aligned}
    \text{Normal vector: } &amp; \mathbf{N} = \nabla w \\
    \text{Unit normal vector: } &amp; \mathbf{\hat n} = \pm
\frac{\mathbf N}{|\mathbf N|} \\
        \text{Project to x-y plane (for instance): } &amp; \Delta A =
\cos \alpha \Delta S
        = \frac{\mathbf{\hat n}\cdot \mathbf{\hat{k}}}{|\mathbf{\hat n}|
|\mathbf{\hat{k}}|} \Delta S  =\mathbf{\hat n}\cdot
\mathbf{\hat{k}}  \Delta S \\
    \implies &amp; \mathrm dS = \frac{1}{\mathbf{\hat n}\cdot
\mathbf{\hat{k}}}\mathrm d x \mathrm d y \\
    \implies &amp; \mathrm dS = \pm \frac{|\mathbf N|}{\mathbf N \cdot
\mathbf{\hat{k}}} \mathrm d x \mathrm d y \\
    \implies &amp; \mathbf{\hat{n}}\mathrm d S  = \pm \frac{\nabla
w}{\nabla w \cdot \hat k} \mathrm d x \mathrm d y
\end{aligned}
\]</span></p>
<h3 id="divergence-theorem">Divergence theorem</h3>
<p>For <span class="math inline">\(F = P\vec i + Q \vec j + R \vec
k\)</span>:</p>
<p><span class="math display">\[
div(\vec{F}) = P_x + Q_y + R_z = \nabla \cdot \vec F
\]</span></p>
<p>For a closed surface <span class="math inline">\(S\)</span> bounding
region <span class="math inline">\(R\)</span>, with normal pointing
outwards, and <span class="math inline">\(\vec F\)</span> vector field
defined and differentiable over all of <span
class="math inline">\(R\)</span>:</p>
<p><span class="math display">\[
{\subset\!\supset} \llap{\iint}_S \vec{F}\cdot\mathbf{\hat{n}}\mathrm d
S = \iiint_R \nabla \cdot \vec F \mathrm d V
\]</span></p>
<h3 id="diffusion-equation">Diffusion equation</h3>
<p>For motion of smoke in (immobile) air, where <span
class="math inline">\(u(x, y, z, t)\)</span> is concentration of smoke,
<span class="math inline">\(\mathbf{F}\)</span> is flow of smoke:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathbf{F} = -k \nabla u \\
&amp; \iint_S \mathbf{F}\cdot \mathbf{\hat{n}} \mathrm d S =
-\frac{\mathrm d}{\mathrm d t}\iiint_Ru\mathrm d V \\
\implies &amp; \frac{\partial u}{\partial t} = - div \mathbf{F} =  k
\nabla^2 u = k(\frac{\partial ^ 2 u}{\partial x ^ 2} + \frac{\partial ^
2 u}{\partial y ^ 2} + \frac{\partial ^ 2 u}{\partial z ^ 2})
\end{aligned}
\]</span></p>
<h3 id="curl-in-3d-space">Curl in 3D space</h3>
<p><span class="math display">\[
curl(\vec F) = \nabla \times \mathbf{F} =
    \begin{vmatrix}
        \mathbf{\hat i} &amp; \mathbf{\hat j} &amp; \mathbf{\hat k} \\
        \frac \partial {\partial x} &amp; \frac \partial {\partial y}
&amp; \frac \partial {\partial z} \\
        P &amp; Q &amp; R
    \end{vmatrix} = (R_y- Q_z)\mathbf{\hat i} + (P_z - R_x)\mathbf{\hat
j} + (Q_x - P_y) \mathbf{\hat k}
\]</span></p>
<h3 id="stokes-theorem">Stokes theorem</h3>
<p>For a closed curve <span class="math inline">\(C\)</span>, and any
surface <span class="math inline">\(S\)</span> bounded by <span
class="math inline">\(C\)</span>, then:</p>
<p><span class="math display">\[
\oint_C \mathbf{F}\cdot \mathrm d \vec{r} = \iint_S (\nabla \times
\mathbf{F})\cdot \mathbf{\hat n} \mathrm d S
\]</span></p>
<h1 id="linear-algebra-mit-18.06">Linear Algebra (<a
href="https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/">MIT
18.06</a>)</h1>
<h2 id="vectors">Vectors</h2>
<h3 id="notation">Notation</h3>
<p>2 seprate numbers <span class="math inline">\(v_1\)</span> and <span
class="math inline">\(v_2\)</span> produces a <em>two-dimensinal
vector</em> <span class="math inline">\(\mathbf{v} = \begin{bmatrix} v_1
\\ v_2 \end{bmatrix}\)</span>; it can be written as <span
class="math inline">\(\mathbf{v} = (v_1, v_2)\)</span>.</p>
<!-- If the $\mathbf{v}_k$ is not the linear conbination of the $\mathbf{v}_1,\cdots,\mathbf{v}_{k-1}$ in $k$ dimention space, then the 1..k fill the k-dimention space in n-dimention space. -->
<h3 id="dot-product">Dot product</h3>
<p><span class="math display">\[
\mathbf{v}\cdot \mathbf{w} = \sum_i v_iw_i
\]</span></p>
<h3 id="length">Length</h3>
<p><span class="math display">\[
\lVert \mathbf{v}\rVert = \sqrt{\mathbf{v}\cdot\mathbf{v}}
\]</span></p>
<h3 id="angle">Angle</h3>
<p><span class="math display">\[
\cos \theta = \frac{\mathbf{v}\cdot\mathbf{w}}{\lVert\mathbf{v}\rVert
\lVert\mathbf{w}\rVert}
\]</span></p>
<h2 id="matrices">Matrices</h2>
<h3 id="multiplication">Multiplication</h3>
<p><span class="math display">\[
\begin{aligned}
    \mathbf C &amp;= \mathbf{AB} \\
    \mathbf C_{ij} &amp;= \sum_{k} \mathbf{A}_{ik}\mathbf B_{kj}
\end{aligned}
\]</span></p>
<p>Fundamental law of matrix multiplication:</p>
<p><span class="math display">\[
(\mathbf{AB})\mathbf C = \mathbf{A} (\mathbf{BC})
\]</span></p>
<h3 id="matrix-elementary-transformations">Matrix elementary
transformations</h3>
<ol type="1">
<li>Row interchange, <span class="math inline">\(R_i \leftrightarrow
R_j\)</span> ;</li>
<li>Row scale, <span class="math inline">\(R_i \rightarrow kR_i\)</span>
;</li>
<li>Row addition, <span class="math inline">\(R_i \rightarrow R_i +
kR_j\)</span> .</li>
</ol>
<h3 id="gauss-elimination-for-mathbfax-mathbf-b">Gauss elimination (for
<span class="math inline">\(\mathbf{Ax} = \mathbf b\)</span>)</h3>
<p>To use the elementary transformations to make the matrix a upper
triangular matrix. Each single step of transformation can be expressed
as one matrix, <span class="math inline">\(\Pi_{i} \mathbf{E_i} \cdot
\mathbf A = \mathbf U\)</span>.</p>
<p><span class="math display">\[
\mathbf E \left[ \mathbf{Ax}, \mathbf b \right] = \left[ \mathbf {Ux},
\mathbf{Eb} \right]
\]</span></p>
<h3 id="gauss-jordan-elimination-for-mathbfa-1">Gauss-Jordan elimination
(for <span class="math inline">\(\mathbf{A^{-1}}\)</span>)</h3>
<p>To use the elementary transformations to make the matrix an identity
matrix. Again, transformation can be expressed as one matrix, <span
class="math inline">\(\Pi_{i} \mathbf{E_i} \cdot \mathbf A = \mathbf I
\iff \Pi_{i} \mathbf{E_i} = \mathbf{A^{-1}}\)</span>.</p>
<p><span class="math display">\[
\mathbf E \left[ \mathbf{A}, \mathbf I \right] = \left[ \mathbf{I},
\mathbf A^{-1} \right]
\]</span></p>
<h3 id="mathbf-pa-mathbflu-factorization"><span
class="math inline">\(\mathbf {PA} = \mathbf{LU}\)</span>
factorization</h3>
<p>All non-singular square matrices can be factorized to <span
class="math inline">\(\mathbf {PA} = \mathbf{LU}\)</span> format. <span
class="math inline">\(\mathbf P\)</span> is the permutation matrix.</p>
<h2 id="vector-space-and-subspace">Vector Space and Subspace</h2>
<h3 id="space-of-vectors">Space of vectors</h3>
<p>The vector space <span class="math inline">\(\mathbb{R}^n\)</span>
consists of all column vectors <span
class="math inline">\(\mathbf{v}\)</span> with <span
class="math inline">\(n\)</span> components.</p>
<p>Linear combinations of vectors of space <span
class="math inline">\(\mathbf S\)</span> must be in <span
class="math inline">\(\mathbf S\)</span>.</p>
<h3 id="subspaces">Subspaces</h3>
<p>A <em>subspace</em> of a vector space is a set of vectors (including
<span class="math inline">\(\mathbf 0\)</span>) that satisfies two
requirements: <em>If <span class="math inline">\(\mathbf{v}\)</span> and
<span class="math inline">\(\mathbf{w}\)</span> are vectors in the
subspace and <span class="math inline">\(c\)</span> is any scalar,
then</em> - <span class="math inline">\(\mathbf{v} + \mathbf{w}\)</span>
is in the subspace - <span class="math inline">\(c\mathbf{v}\)</span> is
in the subspace.</p>
<p>A <em>subspace</em> of <span class="math inline">\(\mathbf R
^n\)</span> is a vector space inside <span class="math inline">\(\mathbf
R ^n\)</span>.</p>
<p>Intersection of subspaces is a subspace.</p>
<h3 id="column-space">Column space</h3>
<p>The <em>column space</em> <span
class="math inline">\(C(\mathbf{A})\)</span> contain all combinations of
the columns of <span class="math inline">\(\mathbf A\)</span>: a
subspace of <span class="math inline">\(\mathbf R ^ m\)</span>.</p>
<p>The system <span class="math inline">\(\mathbf{A}\mathbf{x} =
\mathbf{b}\)</span> is solvable <span
class="math inline">\(\iff\)</span> <span
class="math inline">\(\mathbf{b}\)</span> is in the column space of
<span class="math inline">\(\mathbf{A}\)</span>.</p>
<h3 id="null-space">Null space</h3>
<p>The <em>null space</em> <span
class="math inline">\(N(\mathbf{A})\)</span> contains all solutions
<span class="math inline">\(\mathbf{x}\)</span> to <span
class="math inline">\(\mathbf A\mathbf{x}=\mathbf{0}\)</span>, which
contains <span class="math inline">\(\mathbf{x}=\mathbf{0}\)</span>.</p>
<h3 id="echelon-matrix-mathbfr">Echelon matrix <span
class="math inline">\(\mathbf{R}\)</span></h3>
<p><span class="math display">\[
R = \begin{bmatrix}
1 &amp; 0 &amp; a &amp; 0 &amp; c \\
0 &amp; 1 &amp; b &amp; 0 &amp; d \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; e \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
\quad
s_1 = \begin{bmatrix}
-a \\
-b \\
1 \\
0 \\
0
\end{bmatrix}
\quad
s_2 = \begin{bmatrix}
-c \\
-d \\
0 \\
-e \\
1
\end{bmatrix}
\]</span></p>
<p>The <em>reduced row echelon form</em> <span
class="math inline">\(\mathbf{R} = \mathbf{rref}(A)\)</span> has all
pivots as <span class="math inline">\(1\)</span>, with <span
class="math inline">\(0\)</span> above and below.</p>
<p>If column <span class="math inline">\(j\)</span> of <span
class="math inline">\(\mathbf{R}\)</span> is free, there is a
<em>particular solution</em> to <span
class="math inline">\(A\mathbf{x}=\mathbf{0}\)</span> with <span
class="math inline">\(x_j = 1\)</span>; as above.</p>
<p>Number of pivots = nonzero rows in <span
class="math inline">\(\mathbf R\)</span> = <em>rank</em> <span
class="math inline">\(r\)</span>, then there is <span
class="math inline">\(n-r\)</span> free columns.</p>
<h3 id="mathbf-amathbfxmathbfb"><span class="math inline">\(\mathbf
A\mathbf{x}=\mathbf{b}\)</span></h3>
<p><span class="math display">\[x_p\text{ (one particular
solution)}+\text{ linear combinations of } x_n \text{ (in the null
space)}\]</span></p>
<p><span class="math inline">\(\mathbf E \left[ \mathbf{A}, \mathbf x
\right] = \left[ \mathbf{R}, \mathbf d\right]\)</span>: <span
class="math inline">\(\mathbf{A}/\mathbf{R}\)</span> is solvable <span
class="math inline">\(\iff\)</span> all zero rows of <span
class="math inline">\(\mathbf{R}\)</span> have zeros in <span
class="math inline">\(\mathbf d\)</span>.</p>
<h3 id="cases-for-mathbf-amathbfxmathbfb">Cases for <span
class="math inline">\(\mathbf A\mathbf{x}=\mathbf{b}\)</span></h3>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Symbol</th>
<th style="text-align: left;">Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(\mathbf{I}\)</span></td>
<td style="text-align: left;">Invertible matrix</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(\mathbf{P}\)</span></td>
<td style="text-align: left;">Column permutation matrix</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\mathbf
F\)</span></td>
<td style="text-align: left;">Free columns</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Condition</th>
<th style="text-align: left;"><span class="math inline">\(\mathbf
R\)</span></th>
<th style="text-align: left;">Solution</th>
<th style="text-align: left;">Note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(n = m =
r\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\left[
\mathbf{I} \right]\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(1\)</span></td>
<td style="text-align: left;">square, invertible</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(r = m, r &lt;
n\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\left[
\mathbf{I} \quad \mathbf{F} \right]\mathbf{P}\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\infty\)</span></td>
<td style="text-align: left;">-</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(r &lt; m, r =
n\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\left[
\begin{array}{c} \mathbf{I} \\ \mathbf{0} \end{array}
\right]\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(0/1\)</span></td>
<td style="text-align: left;">1 <span
class="math inline">\(\iff\)</span> all zero rows of <span
class="math inline">\(\mathbf{R}\)</span> have zeros in <span
class="math inline">\(\mathbf d\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(r &lt; m, r
&lt; n\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\left[
\begin{array}{cc} \mathbf{I} &amp; \mathbf{F} \\ \mathbf{0} &amp;
\mathbf{0} \end{array} \right]\mathbf{P}\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(0/\infty\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\infty\)</span> <span
class="math inline">\(\iff\)</span> all zero rows of <span
class="math inline">\(\mathbf{R}\)</span> have zeros in <span
class="math inline">\(\mathbf d\)</span></td>
</tr>
</tbody>
</table>
<h3 id="independence-basis-dimension">Independence, basis,
dimension</h3>
<h4 id="independence">Independence</h4>
<p><em>Independent columns</em> of <span class="math inline">\(\mathbf
A\)</span> : The only solution to <span class="math inline">\(\mathbf
A\mathbf x = \mathbf 0\)</span> is <span class="math inline">\(\mathbf x
= \mathbf 0\)</span> <span class="math inline">\(\iff\)</span> <span
class="math inline">\(r= n\)</span>. The nullspace is <span
class="math inline">\(\mathbb{Z}\)</span>.</p>
<p><em>Independent vectors</em>: The only zero combination <span
class="math inline">\(\sum c_i \mathbf v_i = \mathbf 0\)</span> has all
<span class="math inline">\(c\)</span>'s = 0.</p>
<h4 id="basis">Basis</h4>
<p>The vectors <span class="math inline">\(\mathbf v_1, \ldots, \mathbf
v_k\)</span> <strong>span the space</strong> <span
class="math inline">\(\mathbf S\)</span> if <span
class="math inline">\(\mathbf S\)</span> = all combinations of the <span
class="math inline">\(\mathbf v\)</span> 's.</p>
<p>The vectors <span class="math inline">\(\mathbf v_1, \ldots, \mathbf
v_k\)</span> are a <em>basis</em> for <span
class="math inline">\(\mathbf S\)</span> if they are independent and
they span <span class="math inline">\(\mathbf S\)</span> .</p>
<h4 id="dimension">Dimension</h4>
<p>The <em>dimension</em> of a space <span class="math inline">\(\mathbf
S\)</span> is the number of vectors in every basis for <span
class="math inline">\(\mathbf S\)</span>, which is the rank of the
matrix.</p>
<h3 id="dimensions-of-the-four-subspaces">Dimensions of the four
subspaces</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Notation</th>
<th style="text-align: left;">Subspace of</th>
<th style="text-align: left;">Dimension</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Column space</td>
<td style="text-align: left;"><span
class="math inline">\(C(\mathbf{A})\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\mathbb{R}^n\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(r\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Row space</td>
<td style="text-align: left;"><span
class="math inline">\(C(\mathbf{A}^\mathtt{T})\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\mathbb{R}^m\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(r\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Null space</td>
<td style="text-align: left;"><span
class="math inline">\(N(\mathbf{A})\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\mathbb{R}^n\)</span></td>
<td style="text-align: left;"><span class="math inline">\(n -
r\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Left null space</td>
<td style="text-align: left;"><span
class="math inline">\(N(\mathbf{A}^\mathtt{T})\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(\mathbb{R}^m\)</span></td>
<td style="text-align: left;"><span
class="math inline">\(m-r\)</span></td>
</tr>
</tbody>
</table>
<p>Elimination produces bases for the row space and nullspace of <span
class="math inline">\(\mathbf{A}\)</span>: They are the same as for
<span class="math inline">\(\mathbf{R}\)</span>.</p>
<p>Elimination often changes the column space and left nullspace (but
dimensions don't change).</p>
<h3 id="rank-1-matrices">Rank 1 matrices</h3>
<p>Rank one matrices: <span class="math inline">\(\mathbf{A} =
\mathbf{u}\mathbf{v}^\mathtt{T} = \text{column times row}\)</span>:
<span class="math inline">\(C(\mathbf{A})\)</span> has basis <span
class="math inline">\(\mathbf{u}\)</span>, <span
class="math inline">\(C(\mathbf{A}^\mathtt{T})\)</span> has basis <span
class="math inline">\(\mathbf{v}\)</span>.</p>
<h2 id="orthogonality">Orthogonality</h2>
<h3 id="vector">Vector</h3>
<p><span class="math display">\[
\mathbf v ^\mathtt{T} \mathbf w = 0 \iff \lVert \mathbf{v} \rVert^2 +
\lVert \mathbf{w} \rVert^2 = \lVert \mathbf{v} + \mathbf{w} \rVert^2
\]</span></p>
<h3 id="subspace">Subspace</h3>
<p>Subspaces <span class="math inline">\(\mathbf{V}\)</span> and <span
class="math inline">\(\mathbf{W}\)</span> are orthogonal when <span
class="math inline">\(\mathbf{v}^\mathtt{T} \mathbf{w} = 0\)</span> for
every <span class="math inline">\(\mathbf{v}\)</span> in <span
class="math inline">\(\mathbf{V}\)</span> and every <span
class="math inline">\(\mathbf{w}\)</span> in <span
class="math inline">\(\mathbf{W}\)</span>.</p>
<p>The row space of <span class="math inline">\(\mathbf{A}\)</span> is
orthogonal to the nullspace, as:</p>
<p><span class="math display">\[
\begin{bmatrix}
    \mathbf{r}_1 \\
    \mathbf{r}_2 \\
    \mathbf{r}_3 \\
    \vdots \\
    \mathbf{r}_m
\end{bmatrix}
\mathbf{x} =
    \begin{bmatrix}
        0 \\
        0 \\
        0 \\
        \vdots \\
        0
    \end{bmatrix}
\]</span></p>
<p>Similarily, the column space is orthogonal to <span
class="math inline">\(N(\mathbf{A}^\mathtt{T})\)</span>.</p>
<p>Nullspace and row space are orthogonal <em>complements</em> in <span
class="math inline">\(\mathbb{R}^n\)</span>.</p>
<h3 id="project-to-vector">Project to vector</h3>
<p>To project <span class="math inline">\(\mathbf b\)</span> to <span
class="math inline">\(\mathbf a\)</span>, assume the projection is <span
class="math inline">\(\mathbf p = p\mathbf a\)</span>, then:</p>
<p><span class="math display">\[
\mathbf a ^\mathtt{T} (\mathbf b - \mathbf p) = \mathbf 0 \iff p =
\frac{\mathbf a ^\mathtt{T}\mathbf b}{\mathbf a^\mathtt{T} \mathbf a}
\iff \mathbf p = \mathbf a \frac{\mathbf a ^\mathtt{T}\mathbf b}{\mathbf
a^\mathtt{T} \mathbf a}
\]</span></p>
<p>Then the projection matrix: <span class="math display">\[
\mathbf P = \frac{\mathbf a \mathbf a ^\mathtt{T}}{\mathbf a^\mathtt{T}
\mathbf a}, \quad r(\mathbf P) = 1, \mathbf P^\mathtt{T} = \mathbf P,
\mathbf P^n = \mathbf P
\]</span></p>
<h3 id="project-to-subspace">Project to subspace</h3>
<p>This is a super set of projecting to vector.</p>
<p>To project <span class="math inline">\(\mathbf b\)</span> to subspace
<span class="math inline">\(\mathbf A\)</span> with basis <span
class="math inline">\(\mathbf a_{1\dots m}\)</span>, assume the
projection is <span class="math inline">\(\mathbf p\)</span>, then:</p>
<p><span class="math display">\[
\mathbf p = \sum_{i = 1}^{m}x_i\mathbf a _i = \mathbf A \mathbf{\hat x}
\]</span></p>
<p><span class="math display">\[
\mathbf a_i^\mathtt{T}(\mathbf b - \mathbf p) = 0, \forall i \in [1..m]
\iff \begin{bmatrix}
    \mathbf{a}_1^\mathtt{T} \\
    \mathbf{a}_2^\mathtt{T} \\
    \mathbf{a}_3^\mathtt{T} \\
    \vdots \\
    \mathbf{a}_m^\mathtt{T}
\end{bmatrix}
(\mathbf b - \mathbf p) =
    \begin{bmatrix}
        0 \\
        0 \\
        0 \\
        \vdots \\
        0
    \end{bmatrix} \iff \mathbf A^\mathtt{T}(\mathbf b - \mathbf p) =
\mathbf 0
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\implies &amp; \mathbf A^\mathtt{T}(\mathbf b - \mathbf A \mathbf{\hat
x}) = \mathbf 0 \iff \mathbf{\hat x} = (\mathbf A ^\mathtt{T} \mathbf A)
^ {-1} \mathbf A ^\mathtt{T} \mathbf b \\
\implies &amp; \mathbf p = \mathbf A (\mathbf A ^\mathtt{T} \mathbf A) ^
{-1} \mathbf A ^\mathtt{T} \mathbf b \\
\implies &amp; \mathbf P = \mathbf A (\mathbf A ^\mathtt{T} \mathbf A) ^
{-1} \mathbf A ^\mathtt{T}
\end{aligned}
\]</span></p>
<h3 id="invertibility-of-mathbfamathttt-mathbfa-todo">Invertibility of
<span class="math inline">\(\mathbf{A}^\mathtt{T} \mathbf{A}\)</span>
TODO</h3>
<p><span class="math inline">\(\mathbf{A}\)</span> has independent
columns or <span class="math inline">\(\text{r}(A) = n\)</span> <span
class="math inline">\(\implies\)</span> <span
class="math inline">\(\mathbf{A}^\mathtt{T} \mathbf{A}\)</span> is
invertible:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathbf{A}^\mathtt{T} \mathbf{A} \text{ is invertible }
\iff  \mathbf{A}^\mathtt{T} \mathbf{A} \mathbf x = \mathbf 0 \implies
\mathbf x = \mathbf 0 \\
&amp; \mathbf{A}^\mathtt{T} \mathbf{A} \mathbf x = \mathbf 0 \implies
\mathbf x ^\mathtt{T} \mathbf{A}^\mathtt{T} \mathbf{A} \mathbf x = 0
\implies (\mathbf{A} \mathbf x)^\mathtt{T} \mathbf{A} \mathbf x = 0
\implies \mathbf{A} \mathbf x = \mathbf 0 \overset{\text{r}(A) = n}
\implies \mathbf x = \mathbf 0\\
\end{aligned}
\]</span></p>
<h3 id="least-squares-approximations">Least squares approximations</h3>
<p><span class="math display">\[
\text {if } \mathbf {Ax} = \mathbf{b} \text{ cannot be solved, }
\text{min} \lVert \mathbf {A \hat x} - \mathbf{b} \rVert \iff \mathbf A
\mathbf{ \hat x } = \mathbf {p} \implies \mathbf{ \hat x } = (\mathbf A
^\mathtt{T} \mathbf A) ^ {-1} \mathbf A ^\mathtt{T} \mathbf b
\]</span></p>
<h3 id="orthogonal-matrices">Orthogonal matrices</h3>
<p>The columns <span class="math inline">\(\textbf q_{1 \dots
n}\)</span> are orthonormal if <span class="math inline">\(\mathbf
q_i^\mathtt{T}\mathbf q _j = \begin{cases}
0,\quad i \ne j \\
1,\quad i = j
\end{cases}\)</span>. Then <span class="math inline">\(\mathbf Q ^
\mathtt T \mathbf Q = \mathbf I\)</span>, <span
class="math inline">\(\lVert \mathbf Q \mathbf x \rVert = \lVert \mathbf
x \rVert\)</span>, and the matrix <span class="math inline">\(\mathbf
P\)</span> projecting <span class="math inline">\(\mathbf b\)</span> to
subspace <span class="math inline">\(\mathbf Q\)</span> is <span
class="math inline">\(\mathbf Q \mathbf Q ^\mathtt{T}\)</span>.</p>
<p>If Q is also square, then <span class="math inline">\(\mathbf Q ^
\mathtt T \mathbf Q = \mathbf I\)</span> and <span
class="math inline">\(\mathbf{Q}^\mathtt T =
\mathbf{Q}^{-1}\)</span>.</p>
<h3 id="mathbf-a-mathbf-q-mathbf-r-decomposition"><span
class="math inline">\(\mathbf A = \mathbf Q \mathbf R\)</span>
decomposition</h3>
<p>Gram-Schmidt decomposition can transform any column independent
matrix to <span class="math inline">\(\mathbf Q\)</span> as <span
class="math inline">\(\mathbf Q ^ \mathtt T \mathbf Q = \mathbf
I\)</span>.</p>
<p><span class="math display">\[
\mathbf{A} =
    \begin{bmatrix}
        \mathbf{a}_1 &amp; \mathbf{a}_2 &amp; \cdots &amp;
\mathbf{a}_{n}
    \end{bmatrix}
\quad
\mathbf{Q} =
    \begin{bmatrix}
        \mathbf{q}_1 &amp; \mathbf{q}_2 &amp; \cdots &amp;
\mathbf{q}_{n}
    \end{bmatrix}
\quad
\mathbf q_i = \mathbf q_i - \sum_{j = 1}^{n-1}\frac{\mathbf q_j^\mathtt
T \mathbf q_i}{\mathbf q_j^\mathtt T \mathbf q_j}\mathbf q_j = \mathbf
q_i -  \sum_{j = 1}^{n-1}\mathbf q_j^\mathtt T \mathbf q_i \mathbf q_j,
\mathbf q_i = \frac{\mathbf q_i}{\lVert \mathbf q_i \rVert}
\]</span></p>
<p><span class="math display">\[
\mathbf A \mathbf{ \hat x } = \mathbf {p} \implies \mathbf{ \hat x } =
(\mathbf A ^\mathtt{T} \mathbf A) ^ {-1} \mathbf A ^\mathtt{T} \mathbf
b, \quad \mathbf A = \mathbf Q \mathbf R \implies \mathbf{ \hat x } =
\mathbf R ^{-1} \mathbf Q ^ \mathtt {T} \mathbf b
\]</span></p>
<h2 id="determinants">Determinants</h2>
<h3 id="basic-properties">Basic properties</h3>
<ol type="1">
<li>The determinant of the <span class="math inline">\(n\)</span> by
<span class="math inline">\(n\)</span> identity matrix is 1.</li>
<li>The sign of determinant reverses when two rows are exchanged.</li>
<li>The determinant is a linear function of each row separately, with
all other rows stay fixed:</li>
</ol>
<p><span class="math display">\[
\begin{vmatrix}
ta &amp; tb \\
c &amp; d
\end{vmatrix}
= t \begin{vmatrix}
a &amp; b \\
c &amp; d
\end{vmatrix}
, \quad
\begin{vmatrix} a + a&#39; &amp; b + b&#39; \\ c &amp; d \end{vmatrix} =
\begin{vmatrix} a &amp; b \\ c &amp; d \end{vmatrix} + \begin{vmatrix}
a&#39; &amp; b&#39; \\ c &amp; d \end{vmatrix}
\]</span></p>
<h3 id="derived-properties">Derived properties</h3>
<ol type="1">
<li>If two rows of <span class="math inline">\(\mathbf{A}\)</span> are
equal, then <span class="math inline">\(\det \mathbf{A} =
0\)</span>.</li>
<li>Subtracting a multiple of one row from another row leaves <span
class="math inline">\(\det \mathbf{A}\)</span> unchanged.</li>
<li>A matrix with a row of zeros has <span class="math inline">\(\det
\mathbf{A} = 0\)</span>.</li>
<li>If <span class="math inline">\(\mathbf{A}\)</span> is triangular
then <span class="math inline">\(\det \mathbf{A} = a_{11}a_{22}\cdots
a_{nn} = \text{product of diagonal entries}\)</span>.</li>
<li>If <span class="math inline">\(\mathbf{A}\)</span> is singular then
<span class="math inline">\(\det \mathbf{A} = 0\)</span>. If <span
class="math inline">\(\mathbf{A}\)</span> is invertible then <span
class="math inline">\(\det \mathbf{A} \neq 0\)</span>.</li>
<li>The determinant of <span class="math inline">\(\mathbf{AB}\)</span>
is <span class="math inline">\(\det \mathbf{A}\)</span> times <span
class="math inline">\(\det \mathbf{B}\)</span>: <span
class="math inline">\(\lvert \mathbf{AB} \rvert = \lvert \mathbf{A}
\rvert \lvert \mathbf{B} \rvert\)</span>.</li>
<li>The transpose <span class="math inline">\(\mathbf{A}^\text
T\)</span> has the same determinant as <span
class="math inline">\(\mathbf{A}\)</span>.</li>
</ol>
<h3 id="big-formula">Big formula</h3>
<p><span class="math display">\[
\begin{aligned}
    \det \mathbf{A} &amp; = \text{sum over all } n! \text{ column
permutations } P = (\alpha, \beta, \dots, \omega) \\ &amp;= \sum (\det
P) a_{1\alpha} a_{2\beta} \cdots a_{n\omega}
\end{aligned}
\]</span></p>
<p><span class="math inline">\((\det P)\)</span> is the sign.</p>
<h3 id="cofactor">Cofactor</h3>
<p><span class="math display">\[C_{ij} = (-1)^{i+j} \det \mathbf
M_{ij}\]</span> <span class="math display">\[\det \mathbf{A} =
a_{i1}C_{i1} + a_{i2}C_{i2} + \cdots + a_{in}C_{in}\]</span></p>
<p><span class="math inline">\(\mathbf M_{ij}\)</span> is the matrix
deleting row i and column j.</p>
<h3 id="cramers-rule">Cramer's rule</h3>
<p>To solve <span class="math inline">\(\mathbf A \mathbf x = \mathbf
b\)</span>:</p>
<p><span class="math display">\[
\mathbf{A} \begin{bmatrix} x_1 &amp; 0 &amp; 0 \\ x_2 &amp; 1 &amp; 0 \\
x_3 &amp; 0 &amp; 1 \end{bmatrix} =
\begin{bmatrix}
b_1 &amp; a_{12} &amp; a_{13} \\
b_2 &amp; a_{22} &amp; a_{23} \\
b_3 &amp; a_{32} &amp; a_{33}
\end{bmatrix}
= \mathbf{B}_1 \implies x_1 = \frac {|\mathbf B _1|}{|\mathbf A|}
\implies x_i = \frac {|\mathbf B _i|}{|\mathbf A|}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf b\)</span> be one column of
<span class="math inline">\(\mathbf I\)</span>:</p>
<p><span class="math display">\[
(\mathbf A^{-1})_{ij} = \frac{C_{ji}}{\det \mathbf{A}}
\]</span></p>
<h3 id="area">Area</h3>
<p>A is a <span class="math inline">\(n \times n\)</span> matrix,
rows/columns are the vectors formed an area; <span
class="math inline">\(|\det \mathbf A|\)</span> is the area.</p>
<h2 id="eigen">Eigen</h2>
<h3 id="eigen-vector-and-eigen-value">Eigen vector and eigen value</h3>
<p><span class="math display">\[
\mathbf A \mathbf x = \lambda \mathbf x
\]</span></p>
<p><span class="math inline">\(\mathbf x\)</span> is the eigen vector,
<span class="math inline">\(\lambda\)</span> is the eigen value.</p>
<p><span class="math display">\[
\mathbf A \mathbf x = \lambda \mathbf x \implies (\mathbf A - \lambda
\mathbf I)\mathbf x = \mathbf 0 \implies \mathbf x = \mathbf 0 \lor \det
(\mathbf A - \lambda \mathbf I) = 0
\]</span></p>
<h3 id="texttr-and-textdet"><span
class="math inline">\(\text{tr}\)</span> and <span
class="math inline">\(\text{det}\)</span></h3>
<p><span class="math display">\[
\begin{aligned}
\text{tr} &amp; \mathbf A = \sum_i\mathbf A_{ii} = \sum_i \lambda i \\
\det &amp; \mathbf A = \prod_i \lambda i
\end{aligned}
\]</span></p>
<h3 id="digonalization">Digonalization</h3>
<p><span class="math inline">\(\mathbf S\)</span> is the column matrix
of eigen vectors of <span class="math inline">\(\mathbf A\)</span>:</p>
<p><span class="math display">\[
\mathbf A \mathbf S = \mathbf S \mathbf{\Lambda} \implies \mathbf A =
\mathbf S \mathbf{\Lambda} \mathbf S ^{-1}, \mathbf{\Lambda} = \mathbf S
^{-1} \mathbf A \mathbf S
\]</span></p>
<p>If <span class="math inline">\(\mathbf A\)</span> has <span
class="math inline">\(n\)</span> non-equal eigen values, then <span
class="math inline">\(\mathbf A\)</span> must be digonalizable. If not,
<span class="math inline">\(\mathbf A\)</span> might be
digonlizable.</p>
<h3 id="symmetric-matrices">Symmetric matrices</h3>
<p>The eigen values are real, and the eigen vectors can be chosen as
perpendicular, and:</p>
<p><span class="math display">\[
\mathbf A = \mathbf Q \mathbf{\Lambda} \mathbf Q ^{-1} = \mathbf Q
\mathbf{\Lambda} \mathbf Q ^{\text T}
\]</span></p>
<p>Proof of real eigen values, given <span class="math inline">\(\textbf
A\)</span> is real and symmetric:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; \mathbf A \mathbf x = \lambda \mathbf x \\
    {\text{take conjugate, multiply }\mathbf {\overline x^{\text T}}}
\quad \implies &amp; \mathbf A \mathbf {\overline x} = \overline \lambda
\mathbf {\overline x}, \quad \mathbf {\overline x^{\text T}} \mathbf A
\mathbf x = \lambda \mathbf {\overline x^{\text T}} \mathbf x \\
    {\text{use symmetry, multiply } \mathbf x} \quad \implies &amp;
\mathbf {\overline x ^{\text T}} \mathbf A = \mathbf {\overline x
^{\text T}} \overline \lambda, \quad \mathbf {\overline x^{\text T}}
\mathbf A \mathbf x = \overline \lambda \mathbf {\overline x ^{\text T}}
\mathbf x \\
    {\text{left are same}} \quad \implies &amp; \overline \lambda =
\lambda \implies \lambda \in \mathbb{R}
\end{aligned}
\]</span></p>
<p>Proof of perpendicular, given <span class="math inline">\(\mathbf
S\mathbf x=\lambda_1\mathbf x, \mathbf S\mathbf y=\lambda_2\mathbf
y\)</span>:</p>
<p><span class="math display">\[
\lambda_1\mathbf x^\text T \mathbf y = (\lambda_1\mathbf x)^\text T
\mathbf y = (\mathbf S \mathbf x) ^ \text T \mathbf y = \mathbf x ^
\text T \mathbf S \mathbf y = \mathbf x ^ \text T\lambda_2\mathbf y =
\lambda_2 \mathbf x ^ \text T \mathbf y
\implies \mathbf x ^ \text T \mathbf y = \mathbf 0
\]</span></p>
<h3 id="positive-definite-matrices">Positive definite matrices</h3>
<p>Positive definite matrices are symmetric matrices with:</p>
<ol type="1">
<li>all eigen values &gt; 0; or</li>
<li>all pivots &gt; 0; or</li>
<li>all upper left determinants &gt; 0; or</li>
<li><span class="math inline">\(\textbf x ^ \text T \mathbf S \mathbf x
&gt; 0, \forall x \neq \textbf 0\)</span>.</li>
<li><span class="math inline">\(\mathbf A ^ \text T \mathbf A\)</span>,
if <span class="math inline">\(\mathbf A\)</span> is column
independent.</li>
</ol>
<p>Application for positive definite matrices:</p>
<p><span class="math inline">\(f(x_i)\)</span> has a minimum at <span
class="math inline">\(x=x_0\)</span> if <span
class="math inline">\(\frac{\partial f}{\partial x_i}|_{x_0} =
0\)</span> and matrix <span class="math inline">\(\textbf
S(x_0)\)</span>, which is <span class="math inline">\(S_{ij}(x_0) =
\frac{\partial ^2f}{\partial x_i\partial x_j}|_{x_0}\)</span>, is
positive definite.</p>
<h3 id="similar-matrices">Similar matrices</h3>
<p>For <span class="math inline">\(n\times n\)</span> matrix <span
class="math inline">\(\mathbf A, \mathbf B\)</span>, if there is <span
class="math inline">\(\mathbf M\)</span> which <span
class="math inline">\(\mathbf B = \mathbf M ^ {-1} \mathbf A \mathbf
M\)</span>, then <span class="math inline">\(\mathbf A, \mathbf
B\)</span> are similar. They have some eigen values.</p>
<h2 id="svd">SVD</h2>
<h2 id="complex-matrices">Complex Matrices</h2>
<p>Length:</p>
<p><span class="math display">\[
\lVert \mathbf z \rVert ^ 2 = \overline {\mathbf z} ^ \text T \mathbf{z}
= \mathbf z ^ \text H \mathbf z
\]</span></p>
<p>Inner product:</p>
<p><span class="math display">\[
\mathbf x ^ \text H \mathbf y = \sum \overline x_i y_i
\]</span></p>
<h3 id="unit-root">Unit root</h3>
<p><span class="math display">\[
\omega^n=1 \implies \omega_k = \mathrm{e}^{\mathrm
i\cdot2\pi\cdot\frac{k}{n}}, 0 \leq k \leq n - 1, k\in \mathbb Z
\]</span></p>
<h3 id="hermitian-matrices-mathbf-s-mathbf-s-text-h">Hermitian matrices
<span class="math inline">\(\mathbf S = \mathbf S ^ \text
H\)</span></h3>
<p>The eigen values are real, and the eigen vectors can be chosen as
perpendicular.</p>
<h3 id="unitary-matrices">Unitary matrices</h3>
<p>A unitary matrix is a complex square matrix that has orthonormal
columns.</p>
<p><span class="math display">\[
\mathbf Q ^ \text H = \mathbf Q ^ {-1}
\]</span></p>
<h3 id="fourier-matrix">Fourier matrix</h3>
<p>Fourier matrix is like:</p>
<p><span class="math display">\[
\mathbf F_n = \frac{1}{\sqrt{n}} \begin{pmatrix}
1 &amp; 1 &amp; 1 &amp; \dots &amp; 1 \\
1 &amp; \omega &amp; \omega^2 &amp; \dots &amp; \omega^{n-1} \\
1 &amp; \omega^2 &amp; \omega^4 &amp; \dots &amp; \omega^{2(n-1)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; \omega^{n-1} &amp; \omega^{2(n-1)} &amp; \dots &amp;
\omega^{(n-1)(n-1)}
\end{pmatrix}, \omega = \mathrm{e}^{\mathrm i\cdot2\pi\cdot\frac{1}{n}}
\]</span></p>
<p>Or:</p>
<p><span class="math display">\[
F^{-1}_{xy} = \frac{1}{\sqrt{n}} \omega^{xy}
\]</span></p>
<p>Fourier matrix is unitary matrix as, for column <span
class="math inline">\(0\leq p, q\leq n -1\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; \mathbf F_p ^ \text H \mathbf F_q = \frac 1 n
\sum_{k=0}^{n-1}\overline{\omega ^ {pk}}\omega ^{qk}, \quad
    \overline{\omega ^ {pk}} = \mathrm{e}^{\mathrm
-i\cdot2\pi\cdot\frac{pk}{n}} = \omega^{-pk} \\
    \implies &amp; \mathbf F_p ^ \text H \mathbf F_q = \frac 1 n
\sum_{k=0}^{n-1}\omega^{-pk}\omega ^{qk} = \frac 1
n\sum_{k=0}^{n-1}\omega^{(q-p)k} \\
    \implies &amp; \mathbf F_p ^ \text H \mathbf F_q =
    \begin{cases}
        \frac 1 n \sum_{k=0}^{n-1} \omega ^0 = 1, \quad p = q \\
        \frac 1 n \sum_{k=0}^{n-1} \omega ^ {(q - p)k} = \frac 1 n
\frac{1 - \omega^{(q-p)n}}{1 - \omega^{q-p}} = 0, \quad p \neq q \\
    \end{cases}
\end{aligned}
\]</span></p>
<p>So,</p>
<p><span class="math display">\[
\mathbf F_n^{-1} = \mathbf{F}^\text H \iff F^{-1}_{xy} =
\frac{1}{\sqrt{n}} \omega^{-xy}
\]</span></p>
<h3 id="fft">FFT</h3>
<p>For <span class="math inline">\(\textbf y = \mathbf F_n\textbf
a\)</span> (point-value representation to coefficient
representation):</p>
<p><span class="math display">\[
\begin{aligned}
\sqrt{n} \cdot \textbf y_j &amp; = \sum_{k=0}^{n-1} \omega_n^{jk}\cdot
\textbf a_k \\
    &amp; = \sum_{k = 0}^{\frac n 2 -1}\omega^{2jk}_{n}\textbf a_{2k} +
\omega_n^j\sum_{k = 0}^{\frac n 2 -1}\omega^{2jk}_{n}\textbf a_{2k+1} \\
    &amp; = \sum_{k = 0}^{\frac n 2 -1}\omega^{jk}_{\frac n 2}\textbf
a_{2k} + \omega_n^j \sum_{k = 0}^{\frac n 2 -1}\omega^{jk}_{\frac n
2}\textbf a_{2k+1}, \quad 0 \leq j \leq n - 1\\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(j = j+\frac n 2\)</span> to last line
of above:</p>
<p><span class="math display">\[
\begin{aligned}
\sqrt{n} \cdot \textbf y _{j+\frac n 2} &amp; = \sum_{k = 0}^{\frac n 2
-1}\omega^{(j+\frac n 2)k}_{\frac n 2}\textbf a_{2k} + \omega_n^{j+\frac
n 2} \sum_{k = 0}^{\frac n 2 -1}\omega^{(j+\frac n 2)k}_{\frac n
2}\textbf a_{2k+1}, \quad 0 \leq j \leq \frac n 2 - 1\\
\end{aligned}
\]</span></p>
<p>And there is <span class="math inline">\(\omega^{(j+\frac n
2)k}_{\frac n 2} = \omega_{\frac n 2}^{jk +\frac n 2 k} =  \omega_{\frac
n 2}^{jk}\cdot(\omega_{\frac n 2}^{\frac n 2})^k = \omega_{\frac n
2}^{jk}\)</span> and <span class="math inline">\(\omega_n^{j+\frac n 2}=
\omega_n^{j}\cdot\omega^{\frac n 2}_n = -\omega_n^j\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\sqrt{n} \cdot \textbf y _{j+\frac n 2} &amp; = \sum_{k = 0}^{\frac n 2
-1}\omega^{jk}_{\frac n 2}\textbf a_{2k} -\omega_n^j \sum_{k = 0}^{\frac
n 2 -1}\omega^{jk}_{\frac n 2}\textbf a_{2k+1}, \quad 0 \leq j \leq
\frac n 2 - 1\\
\end{aligned}
\]</span></p>
<p>So:</p>
<p><span class="math display">\[
\begin{aligned}
\sqrt{n} \cdot\textbf y _j &amp; = \sum_{k = 0}^{\frac n 2
-1}\omega^{jk}_{\frac n 2}\textbf a_{2k} + \omega_n^j \sum_{k =
0}^{\frac n 2 -1}\omega^{jk}_{\frac n 2}\textbf a_{2k+1} = [\textbf
F_{\frac n 2}a&#39;]_j + \omega_n^j[ F_{\frac n 2}a&#39;&#39;]_j =
\textbf{y}&#39;_j + \omega_n^j \textbf{y}&#39;&#39;_j, \quad 0 \leq j
\leq \frac n 2 - 1 \\
\sqrt{n} \cdot \textbf y _{j+\frac n 2} &amp; = \sum_{k = 0}^{\frac n 2
-1}\omega^{jk}_{\frac n 2}\textbf a_{2k} -\omega_n^j \sum_{k = 0}^{\frac
n 2 -1}\omega^{jk}_{\frac n 2}\textbf a_{2k+1} = [\textbf F_{\frac n
2}a&#39;]_j - \omega_n^j[ F_{\frac n 2}a&#39;&#39;]_j =
\textbf{y}&#39;_j - \omega_n^j\textbf{y}&#39;&#39;_j, \quad 0 \leq j
\leq \frac n 2 - 1\\
\end{aligned}
\]</span></p>
<h1 id="discrete-mathematics-mit-6.042">Discrete Mathematics (<a
href="https://ocw.mit.edu/courses/6-042j-mathematics-for-computer-science-fall-2010/">MIT
6.042</a>)</h1>
<h1 id="probability-mit-6.041">Probability (<a
href="https://ocw.mit.edu/courses/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video_galleries/video-lectures/">MIT
6.041</a>)</h1>
<h1 id="theory-of-computation-mit-18.404">Theory of Computation (<a
href="https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/video_galleries/video-lectures/">MIT
18.404</a>)</h1>

      </div>
      
      
      
    </div>
    

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#calculus-i-mit-18.01"><span class="nav-text">Calculus I (MIT
18.01)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#differentiation"><span class="nav-text">Differentiation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#limit"><span class="nav-text">Limit</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#derivative"><span class="nav-text">Derivative</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#continuity"><span class="nav-text">Continuity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#conputations-of-derivatives"><span class="nav-text">Conputations of derivatives</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#higher-derivative-notation"><span class="nav-text">Higher derivative notation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inplicit-differentication"><span class="nav-text">Inplicit differentication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#derivative-table"><span class="nav-text">Derivative table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lhospitals-rule"><span class="nav-text">L&#39;Hospital&#39;s rule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#differential-notation"><span class="nav-text">Differential notation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#applications-of-differentiation"><span class="nav-text">Applications of
Differentiation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-approximation"><span class="nav-text">Linear approximation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#newtons-method"><span class="nav-text">Newton&#39;s method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mean-value-theorem"><span class="nav-text">Mean value theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#anti-derivaitive-table"><span class="nav-text">Anti-derivaitive table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#differential-in-economics"><span class="nav-text">Differential in economics</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#integration"><span class="nav-text">Integration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#riemann-sum"><span class="nav-text">Riemann sum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#definite-integral"><span class="nav-text">Definite integral</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#first-fundamental-theorem-of-calculus"><span class="nav-text">First fundamental theorem
of calculus</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#second-fundamental-theorem-of-calculus"><span class="nav-text">Second fundamental
theorem of calculus</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#substitution"><span class="nav-text">Substitution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#trigonometric-function-integration"><span class="nav-text">Trigonometric function
integration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#partial-function-integration"><span class="nav-text">Partial function integration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#improper-integral"><span class="nav-text">Improper integral</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#applications-of-integral"><span class="nav-text">Applications of Integral</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#area-between-2-curves"><span class="nav-text">Area between 2 curves</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#volume-by-slice-method"><span class="nav-text">Volume by slice method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#volume-by-disk-method"><span class="nav-text">Volume by disk method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#volume-by-cylinder-method"><span class="nav-text">Volume by cylinder method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#weighted-average"><span class="nav-text">Weighted average</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#simpsons-method"><span class="nav-text">Simpson&#39;s method</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#arc-length"><span class="nav-text">Arc length</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#surface-area-of-a-function-revolved-about-x-axis"><span class="nav-text">Surface area
of a function revolved about \(x\)-axis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#area-in-polar-coordinates"><span class="nav-text">Area in polar coordinates</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#series"><span class="nav-text">Series</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sequence"><span class="nav-text">Sequence</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#series-1"><span class="nav-text">Series</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ratio-test-and-root-test"><span class="nav-text">Ratio test and root test</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alternating-series-test"><span class="nav-text">Alternating series test</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#power-series"><span class="nav-text">Power series</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#integral-comparison"><span class="nav-text">Integral comparison</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eulers-constant"><span class="nav-text">Euler&#39;s constant</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#taylors-series"><span class="nav-text">Taylor&#39;s series</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#miscellaneous"><span class="nav-text">Miscellaneous</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mathrme"><span class="nav-text">\(\mathrm{e}\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#int_-inftyinftye-x2mathrm-d-x"><span class="nav-text">\(\int_{-\infty}^{\infty}e^{-x^2}\mathrm d
x\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#maximum-overhung"><span class="nav-text">Maximum overhung</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#real-number-system"><span class="nav-text">Real number system</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#calculus-ii-mit-18.02"><span class="nav-text">Calculus II (MIT
18.02)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#vectors-and-matrices"><span class="nav-text">Vectors and Matrices</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#product"><span class="nav-text">Product</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#determinant"><span class="nav-text">Determinant</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inverse-matrix"><span class="nav-text">Inverse matrix</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#partial-derivatives"><span class="nav-text">Partial Derivatives</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#partial-derivaitives"><span class="nav-text">Partial derivaitives</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#least-square"><span class="nav-text">Least square</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#minmax"><span class="nav-text">Min&#x2F;max</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#taylors-theorem"><span class="nav-text">Taylor&#39;s theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#total-differential"><span class="nav-text">Total differential</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chain-rule"><span class="nav-text">Chain rule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gradient-vector"><span class="nav-text">Gradient vector</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rate-of-change-in-an-arbitrary-direction"><span class="nav-text">Rate of change in an
arbitrary direction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lagarange-multipliers"><span class="nav-text">Lagarange multipliers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#partial-derivative-with-non-indenpendent-variables"><span class="nav-text">Partial
derivative with non-indenpendent variables</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#double-integral-in-plane"><span class="nav-text">Double Integral in Plane</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#double-integral"><span class="nav-text">Double integral</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#polar-coordinates"><span class="nav-text">Polar coordinates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#area-of-region"><span class="nav-text">Area of region</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#center-of-mass"><span class="nav-text">Center of mass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rotational-moment-of-inertia"><span class="nav-text">Rotational moment of inertia</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#jcaobian-matrix"><span class="nav-text">Jcaobian matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#change-of-variables"><span class="nav-text">Change of variables</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#line-integral-in-plane"><span class="nav-text">Line Integral in Plane</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#vector-fields"><span class="nav-text">Vector fields</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#line-integral"><span class="nav-text">Line integral</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fundamental-theorem-of-calculus-for-line-integrals"><span class="nav-text">Fundamental
theorem of calculus for line integrals</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#curl"><span class="nav-text">Curl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#greens-theorem"><span class="nav-text">Green&#39;s theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flux"><span class="nav-text">Flux</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#div"><span class="nav-text">Div</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#greens-theorem-for-flux"><span class="nav-text">Green&#39;s theorem for flux</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#triple-integrals-and-surface-integrals-in-3d-space"><span class="nav-text">Triple
Integrals and Surface Integrals in 3D-Space</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#triple-integrals"><span class="nav-text">Triple integrals</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cylindrical-and-spherical-coordinates"><span class="nav-text">Cylindrical and spherical
coordinates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vector-fields-in-3d-space"><span class="nav-text">Vector fields in 3D space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flux-in-3d-space"><span class="nav-text">Flux in 3D space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#divergence-theorem"><span class="nav-text">Divergence theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#diffusion-equation"><span class="nav-text">Diffusion equation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#curl-in-3d-space"><span class="nav-text">Curl in 3D space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#stokes-theorem"><span class="nav-text">Stokes theorem</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#linear-algebra-mit-18.06"><span class="nav-text">Linear Algebra (MIT
18.06)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#vectors"><span class="nav-text">Vectors</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#notation"><span class="nav-text">Notation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dot-product"><span class="nav-text">Dot product</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#length"><span class="nav-text">Length</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#angle"><span class="nav-text">Angle</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#matrices"><span class="nav-text">Matrices</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#multiplication"><span class="nav-text">Multiplication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#matrix-elementary-transformations"><span class="nav-text">Matrix elementary
transformations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gauss-elimination-for-mathbfax-mathbf-b"><span class="nav-text">Gauss elimination (for
\(\mathbf{Ax} &#x3D; \mathbf b\))</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gauss-jordan-elimination-for-mathbfa-1"><span class="nav-text">Gauss-Jordan elimination
(for \(\mathbf{A^{-1}}\))</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mathbf-pa-mathbflu-factorization"><span class="nav-text">\(\mathbf {PA} &#x3D; \mathbf{LU}\)
factorization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#vector-space-and-subspace"><span class="nav-text">Vector Space and Subspace</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#space-of-vectors"><span class="nav-text">Space of vectors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#subspaces"><span class="nav-text">Subspaces</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#column-space"><span class="nav-text">Column space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#null-space"><span class="nav-text">Null space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#echelon-matrix-mathbfr"><span class="nav-text">Echelon matrix \(\mathbf{R}\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mathbf-amathbfxmathbfb"><span class="nav-text">\(\mathbf
A\mathbf{x}&#x3D;\mathbf{b}\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cases-for-mathbf-amathbfxmathbfb"><span class="nav-text">Cases for \(\mathbf A\mathbf{x}&#x3D;\mathbf{b}\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#independence-basis-dimension"><span class="nav-text">Independence, basis,
dimension</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#independence"><span class="nav-text">Independence</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#basis"><span class="nav-text">Basis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dimension"><span class="nav-text">Dimension</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dimensions-of-the-four-subspaces"><span class="nav-text">Dimensions of the four
subspaces</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rank-1-matrices"><span class="nav-text">Rank 1 matrices</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#orthogonality"><span class="nav-text">Orthogonality</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#vector"><span class="nav-text">Vector</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#subspace"><span class="nav-text">Subspace</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#project-to-vector"><span class="nav-text">Project to vector</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#project-to-subspace"><span class="nav-text">Project to subspace</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#invertibility-of-mathbfamathttt-mathbfa-todo"><span class="nav-text">Invertibility of
\(\mathbf{A}^\mathtt{T} \mathbf{A}\)
TODO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#least-squares-approximations"><span class="nav-text">Least squares approximations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#orthogonal-matrices"><span class="nav-text">Orthogonal matrices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mathbf-a-mathbf-q-mathbf-r-decomposition"><span class="nav-text">\(\mathbf A &#x3D; \mathbf Q \mathbf R\)
decomposition</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#determinants"><span class="nav-text">Determinants</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#basic-properties"><span class="nav-text">Basic properties</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#derived-properties"><span class="nav-text">Derived properties</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#big-formula"><span class="nav-text">Big formula</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cofactor"><span class="nav-text">Cofactor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cramers-rule"><span class="nav-text">Cramer&#39;s rule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#area"><span class="nav-text">Area</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#eigen"><span class="nav-text">Eigen</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#eigen-vector-and-eigen-value"><span class="nav-text">Eigen vector and eigen value</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#texttr-and-textdet"><span class="nav-text">\(\text{tr}\) and \(\text{det}\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#digonalization"><span class="nav-text">Digonalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#symmetric-matrices"><span class="nav-text">Symmetric matrices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#positive-definite-matrices"><span class="nav-text">Positive definite matrices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#similar-matrices"><span class="nav-text">Similar matrices</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#svd"><span class="nav-text">SVD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#complex-matrices"><span class="nav-text">Complex Matrices</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#unit-root"><span class="nav-text">Unit root</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hermitian-matrices-mathbf-s-mathbf-s-text-h"><span class="nav-text">Hermitian matrices
\(\mathbf S &#x3D; \mathbf S ^ \text
H\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unitary-matrices"><span class="nav-text">Unitary matrices</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fourier-matrix"><span class="nav-text">Fourier matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fft"><span class="nav-text">FFT</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#discrete-mathematics-mit-6.042"><span class="nav-text">Discrete Mathematics (MIT
6.042)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#probability-mit-6.041"><span class="nav-text">Probability (MIT
6.041)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#theory-of-computation-mit-18.404"><span class="nav-text">Theory of Computation (MIT
18.404)</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jingqi Chen"
      src="/uploads/avatar.png">
  <p class="site-author-name" itemprop="name">Jingqi Chen</p>
  <div class="site-description" itemprop="description">50% Humanities 50% Science</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hobochen" title="GitHub  https://github.com/hobochen" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hobochen96@gmail.com" title="Email  mailto:hobochen96@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Email</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2013  
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jingqi Chen</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
